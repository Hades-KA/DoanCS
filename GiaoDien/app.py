import streamlit as st
st.set_page_config(page_title="H·ªá th·ªëng H·ªó tr·ª£ Tuy·ªÉn d·ª•ng b·∫±ng AI", layout="wide")

import os
import pdfplumber
import re
import base64
from transformers import pipeline
import pandas as pd
from concurrent.futures import ThreadPoolExecutor
from rapidfuzz import fuzz
from streamlit_option_menu import option_menu
import unicodedata
import matplotlib.pyplot as plt
from collections import Counter

# --- Danh s√°ch k·ªπ nƒÉng l·∫≠p tr√¨nh ph·ªï bi·∫øn ---
COMMON_SKILLS = [
    "javascript", "typescript", "reactjs", "redux", "tailwindcss", "java", "spring boot", "spring", "spring framework",
    "spring security", "spring jpa", "validate", "mysql", "sql server", "antd", "cloudinary", "jwt", "php", "vuejs",
    "html", "css", "nodejs", "python", "docker", "kubernetes", "aws", "azure", "flask", "django", "c#", "c++", "android",
    "ios", "react native", "swift", "kotlin"
]

def extract_present_skills(text):
    text_lower = text.lower()
    present_skills = []
    for skill in COMMON_SKILLS:
        if skill in text_lower and skill not in present_skills:
            present_skills.append(skill)
    return present_skills

# --- CSS tu·ª≥ ch·ªânh ---
st.markdown("""
    <style>
    .stApp { background-color: #181c24; }
    .css-1d391kg, .css-1v0mbdj, .css-1cypcdb { color: #00d4ff !important; }
    .stSidebar { background: #23272f; }
    .sidebar-title { color: #00d4ff; font-size: 22px; font-weight: bold; text-align: center; }
    .sidebar-desc { color: #aaa; font-size: 14px; text-align: center; }
    .stButton>button, .stDownloadButton>button { background: linear-gradient(90deg,#00d4ff,#1e90ff); color: white; }
    .stDataFrame { background-color: #23272f; }
    .metric-label, .metric-value { color: #00d4ff !important; }
    .stProgress > div > div > div > div { background-image: linear-gradient(90deg,#00d4ff,#1e90ff); }
    </style>
""", unsafe_allow_html=True)

# üìÖ Th∆∞ m·ª•c l∆∞u CV
UPLOAD_FOLDER = './uploaded_cvs/'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# üìö Load m√¥ h√¨nh AI
@st.cache_resource
def load_classifier():
    try:
        return pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh AI: {str(e)}. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi m·∫°ng ho·∫∑c th·ª≠ l·∫°i sau.")
        return None

classifier = load_classifier()
FIELDS = ["Frontend Development", "Backend Development", "Data Science/AI", "DevOps", "Mobile Development"]

# --- H√†m l∆∞u file ---
def save_uploadedfile(uploadedfile):
    path = os.path.join(UPLOAD_FOLDER, uploadedfile.name)
    with open(path, "wb") as f:
        f.write(uploadedfile.getbuffer())
    return path

# --- H√†m x·ª≠ l√Ω PDF ---
def extract_text_from_pdf(file_path):
    try:
        text = ""
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages[:3]:  # Ch·ªâ ƒë·ªçc 3 trang ƒë·∫ßu
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text.strip()
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file PDF: {str(e)}")
        return ""

# --- Tr√≠ch xu·∫•t t√™n ---
def extract_name(text):
    lines = text.strip().split("\n")
    for line in lines[:10]:
        for line in lines[:30]:
            if re.search(r"(Name|T√™n):", line, re.IGNORECASE):
                return line.split(":")[-1].strip()
    for line in lines[:10]:
        for line in lines[:30]:
            if len(line.split()) >= 2 and line[0].isupper():
                if not any(char.isdigit() for char in line) and len(line.split()) <= 5 and not any(kw in line.lower() for kw in ["contact", "information"]):
                    if not any(char.isdigit() for char in line) and len(line.split()) <= 5:
                        return line.strip()
    return "Kh√¥ng r√µ"

# --- Ph√¢n lo·∫°i lƒ©nh v·ª±c, tr·∫£ v·ªÅ c·∫£ score ---
def predict_field(text_cv):
    if classifier is None:
        return "Kh√¥ng x√°c ƒë·ªãnh", 0.0
    short_text = text_cv[:300]
    result = classifier(short_text, candidate_labels=FIELDS)
    return result['labels'][0], result['scores'][0]

# --- Tr√≠ch xu·∫•t k·ªπ nƒÉng t·ª´ CV (d·ª±a tr√™n danh s√°ch ph·ªï bi·∫øn) ---
def extract_skills_list(text):
    text_lower = text.lower()
    skills = []
    for skill in COMMON_SKILLS:
        if skill in text_lower and skill not in skills:
            skills.append(skill)
    return skills

# --- Tr√≠ch xu·∫•t k·ªπ nƒÉng t·ª´ d·ª± √°n ---
def extract_skills_from_projects(text):
    sections = re.findall(r"(?i)(project|d·ª± √°n)[^\n]*\n+(.*?)(?=\n{2,}|\Z)", text, re.DOTALL)
    all_skills = set()
    for _, section in sections:
        lines = section.split('\n')
        for line in lines:
            if any(kw in line.lower() for kw in ['stack', 'tech', 'technology', 'tools', 'framework', 's·ª≠ d·ª•ng']):
                items = re.split(r'[:,]', line)
                if len(items) > 1:
                    for part in re.split(r'[,/‚Ä¢]', items[1]):
                        skill = part.strip(" -‚Ä¢()")
                        if 1 < len(skill) <= 30:
                            all_skills.add(skill)
    return sorted(all_skills)

# --- So kh·ªõp k·ªπ nƒÉng ---
def normalize_skill(skill):
    skill = unicodedata.normalize('NFKD', skill).encode('ASCII', 'ignore').decode('utf-8')
    return skill.lower().strip()

def match_skills_accurately(candidate_skills, expected_skills, project_skills):
    candidate_skills = list(set(normalize_skill(skill) for skill in candidate_skills))
    expected_skills = list(set(normalize_skill(skill) for skill in expected_skills))
    project_skills = list(set(normalize_skill(skill) for skill in project_skills))

    matched = []
    for expected in expected_skills:
        for candidate in candidate_skills:
            if (
                fuzz.ratio(expected, candidate) >= 50
                or expected in candidate
                or candidate in expected
            ):
                matched.append(expected)
                break

    matched = list(set(matched))
    missing = [s for s in expected_skills if s not in matched]
    missing = [s for s in missing if s not in project_skills]
    missing = list(set(missing))
    coverage = round(len(matched) / len(expected_skills) * 100, 2) if expected_skills else 0
    return matched, missing, coverage

# --- Ki·ªÉm tra lƒ©nh v·ª±c ---
def match_field(text, target_field):
    text = text.lower()
    target_field = target_field.lower()
    field_keywords = {
        "frontend development": ["frontend", "html", "css", "javascript", "react", "angular", "vue"],
        "backend development": ["backend", "node.js", "django", "flask", "spring", "java", "php"],
        "data science/ai": ["data science", "machine learning", "ai", "deep learning", "pandas", "numpy"],
        "devops": ["devops", "docker", "kubernetes", "ci/cd", "aws", "azure", "cloud"],
        "mobile development": ["mobile", "android", "ios", "flutter", "react native", "swift", "kotlin"]
    }
    keywords = field_keywords.get(target_field, [])
    return any(keyword in text for keyword in keywords)

# --- Hi·ªÉn th·ªã file PDF ---
def display_pdf(file_path):
    with open(file_path, "rb") as f:
        base64_pdf = base64.b64encode(f.read()).decode('utf-8')
        pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="700" height="1000" type="application/pdf"></iframe>'
        st.markdown(pdf_display, unsafe_allow_html=True)

# --- Ph√¢n t√≠ch m·ªôt CV ---
def process_cv(file_path, expected_skills, target_field):
    text = extract_text_from_pdf(file_path)
    if text:
        if not match_field(text, target_field):
            return None
        name = extract_name(text)
        candidate_skills = extract_skills_list(text)
        project_skills = extract_skills_from_projects(text)
        total_skills = list(set(candidate_skills + project_skills))
        matched, missing, skill_coverage = match_skills_accurately(total_skills, expected_skills, project_skills)
        present_skills = extract_present_skills(text)
        result_status = "Ph√π h·ª£p" if skill_coverage >= 50 else "Kh√¥ng ph√π h·ª£p"
        return {
            'T√™n file': os.path.basename(file_path),
            'T√™n ·ª©ng vi√™n': name,
            'M·∫£ng IT': target_field,
            'Ph·∫ßn trƒÉm ph√π h·ª£p': skill_coverage,
            'K·∫øt qu·∫£': result_status,
            'K·ªπ nƒÉng hi·ªán c√≥': ', '.join(present_skills),
            'K·ªπ nƒÉng ph√π h·ª£p': ', '.join(matched),
            'K·ªπ nƒÉng c√≤n thi·∫øu': ', '.join(missing),
            'K·ªπ nƒÉng trong project': ', '.join(project_skills)
        }
    return None

# --- Ph√¢n t√≠ch nhi·ªÅu CV ---
@st.cache_data
def analyze_cvs(uploaded_paths, expected_skills, target_field):
    results = []
    warnings = []
    progress_bar = st.progress(0)
    total_files = len(uploaded_paths)
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(process_cv, path, expected_skills, target_field) for path in uploaded_paths]
        for i, future in enumerate(futures):
            result = future.result()
            if result:
                results.append(result)
            else:
                warnings.append(f"‚ö†Ô∏è CV t·∫°i {uploaded_paths[i]} kh√¥ng ƒë·∫°t ti√™u ch√≠ v√† ƒë√£ b·ªã lo·∫°i b·ªè.")
            progress_bar.progress((i + 1) / total_files)
    if warnings:
        st.warning(f"‚ö†Ô∏è C√≥ {len(warnings)} CV ƒë√£ b·ªã lo·∫°i b·ªè do kh√¥ng ƒë·∫°t ti√™u ch√≠.")
        with st.expander("Xem chi ti·∫øt c√°c c·∫£nh b√°o"):
            st.write("\n".join(warnings))
    return pd.DataFrame(results)

# --- Giao di·ªán ch√≠nh ---
def main():
    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/3135/3135715.png", width=100)
        st.markdown("<div class='sidebar-title'>H·ªá th·ªëng Tuy·ªÉn d·ª•ng AI</div>", unsafe_allow_html=True)
        st.markdown("<div class='sidebar-desc'>T·ªëi ∆∞u h√≥a quy tr√¨nh tuy·ªÉn d·ª•ng, l·ªçc CV ·ª©ng vi√™n t·ª± ƒë·ªông b·∫±ng AI.<br>Ti·∫øt ki·ªám th·ªùi gian, n√¢ng cao hi·ªáu qu·∫£!</div>", unsafe_allow_html=True)
        menu = option_menu(
            None,
            ["Ph√¢n t√≠ch CV", "Dashboard b√°o c√°o"],
            icons=["file-earmark-text", "bar-chart"],
            menu_icon="cast", default_index=0,
            styles={
                "container": {"padding": "5px", "background-color": "#222"},
                "icon": {"color": "#00d4ff", "font-size": "20px"},
                "nav-link": {"font-size": "16px", "text-align": "left", "margin":"2px", "--hover-color": "#1e90ff"},
                "nav-link-selected": {"background-color": "#1e90ff", "color": "white"},
            }
        )

    st.title("üìÑ H·ªá th·ªëng H·ªó tr·ª£ Qu·∫£n l√Ω Tuy·ªÉn d·ª•ng b·∫±ng AI")

    # --- Kh·ªüi t·∫°o session_state ---
    if 'last_df' not in st.session_state:
        st.session_state['last_df'] = None
    if 'uploaded_paths' not in st.session_state:
        st.session_state['uploaded_paths'] = []
    if 'expected_skills' not in st.session_state:
        st.session_state['expected_skills'] = []
    if 'target_field' not in st.session_state:
        st.session_state['target_field'] = ""
    if 'sample_cv_path' not in st.session_state:
        st.session_state['sample_cv_path'] = None
    if 'cv_valid_count' not in st.session_state:
        st.session_state['cv_valid_count'] = 0
    if 'cv_invalid_count' not in st.session_state:
        st.session_state['cv_invalid_count'] = 0
    if 'view_page' not in st.session_state:
        st.session_state['view_page'] = 'phuhop'

    if menu == "Ph√¢n t√≠ch CV":
        st.header("üìÑ Ph√¢n t√≠ch CV")

        # --- X·ª≠ l√Ω upload CV ti√™u ch√≠ ---
        if st.session_state['sample_cv_path']:
            st.success(f"ƒê√£ upload CV ti√™u ch√≠: {os.path.basename(st.session_state['sample_cv_path'])}")
            if st.button("X√≥a CV ti√™u ch√≠"):
                st.session_state['sample_cv_path'] = None
                st.session_state['expected_skills'] = []
                st.session_state['target_field'] = ""
        else:
            sample_cv_file = st.file_uploader("üìå T·∫£i l√™n CV ti√™u ch√≠", type="pdf", key="sample_cv_file")
            if sample_cv_file:
                st.session_state['sample_cv_path'] = save_uploadedfile(sample_cv_file)
                sample_cv_text = extract_text_from_pdf(st.session_state['sample_cv_path'])
                st.session_state['expected_skills'] = extract_skills_list(sample_cv_text)
                st.session_state['target_field'], _ = predict_field(sample_cv_text)

        # --- X·ª≠ l√Ω upload c√°c CV ·ª©ng vi√™n ---
        if st.session_state['uploaded_paths']:
            st.success(f"ƒê√£ upload {len(st.session_state['uploaded_paths'])} CV ·ª©ng vi√™n.")
            if st.button("X√≥a t·∫•t c·∫£ CV ·ª©ng vi√™n"):
                st.session_state['uploaded_paths'] = []
        else:
            uploaded_files = st.file_uploader("üìÖ T·∫£i l√™n c√°c CV ·ª©ng vi√™n", type=["pdf"], accept_multiple_files=True, key="uploaded_files")
            if uploaded_files:
                st.session_state['uploaded_paths'] = [save_uploadedfile(f) for f in uploaded_files]

        # --- Hi·ªÉn th·ªã l·∫°i th√¥ng b√°o k·∫øt qu·∫£ ---
        if st.session_state['cv_valid_count'] > 0:
            st.success(f"‚úÖ ƒê√£ ph√¢n t√≠ch {st.session_state['cv_valid_count']} CV h·ª£p l·ªá tr√™n t·ªïng s·ªë {st.session_state['cv_valid_count'] + st.session_state['cv_invalid_count']} CV.")
        if st.session_state['cv_invalid_count'] > 0:
            st.warning(f"‚ö†Ô∏è C√≥ {st.session_state['cv_invalid_count']} CV ƒë√£ b·ªã lo·∫°i b·ªè do kh√¥ng ƒë·∫°t ti√™u ch√≠.")

        # --- Ph√¢n t√≠ch khi ƒë·ªß d·ªØ li·ªáu ---
        if st.session_state['sample_cv_path'] and st.session_state['uploaded_paths']:
            if st.button("üöÄ Ph√¢n t√≠ch CV ·ª©ng vi√™n"):
                expected_skills = st.session_state['expected_skills']
                target_field = st.session_state['target_field']
                uploaded_paths = st.session_state['uploaded_paths']

                with st.spinner("üîé ƒêang ti·∫øn h√†nh ph√¢n t√≠ch CV..."):
                    my_bar = st.progress(0)
                    df = analyze_cvs(uploaded_paths, expected_skills, target_field)
                    my_bar.progress(1.0)

                st.session_state['last_df'] = df
                st.session_state['cv_valid_count'] = len(df)
                st.session_state['cv_invalid_count'] = len(uploaded_paths) - len(df)

        # --- Hi·ªÉn th·ªã k·∫øt qu·∫£ n·∫øu ƒë√£ ph√¢n t√≠ch ---
        if st.session_state['last_df'] is not None and len(st.session_state['last_df']) > 0:
            df = st.session_state['last_df']
            uploaded_paths = st.session_state['uploaded_paths']
            expected_skills = st.session_state['expected_skills']
            target_field = st.session_state['target_field']

            col1, col2 = st.columns(2)
            with col1:
                if st.button("üìã Danh s√°ch ·ª©ng vi√™n ph√π h·ª£p"):
                    st.session_state['view_page'] = 'phuhop'
            with col2:
                if st.button("üìã Danh s√°ch ·ª©ng vi√™n kh√¥ng ph√π h·ª£p"):
                    st.session_state['view_page'] = 'khongphuhop'

            if st.session_state['view_page'] == 'phuhop':
                df_show = df[df['K·∫øt qu·∫£'] == "Ph√π h·ª£p"]
                st.subheader(f"‚úÖ Danh s√°ch ·ª©ng vi√™n ph√π h·ª£p ({len(df_show)})")
            else:
                df_show = df[df['K·∫øt qu·∫£'] == "Kh√¥ng ph√π h·ª£p"]
                st.subheader(f"‚ùå Danh s√°ch ·ª©ng vi√™n kh√¥ng ph√π h·ª£p ({len(df_show)})")

            if df_show.empty:
                st.warning("Kh√¥ng c√≥ ·ª©ng vi√™n trong danh s√°ch n√†y.")
            else:
                df_show = df_show.copy()
                df_show.index = range(1, len(df_show) + 1)
                st.dataframe(df_show)

                st.subheader("üîç Xem chi ti·∫øt t·ª´ng CV")
                selected_file = st.selectbox("Ch·ªçn m·ªôt file CV ƒë·ªÉ xem chi ti·∫øt:", df_show['T√™n file'].tolist())

                if selected_file:
                    selected_path = next((path for path in uploaded_paths if os.path.basename(path) == selected_file), None)
                    if selected_path:
                        text = extract_text_from_pdf(selected_path)
                        if text:
                            st.markdown(f"### üìÑ Ph√¢n t√≠ch chi ti·∫øt CV: `{selected_file}`")
                            display_pdf(selected_path)

                            st.markdown(
                                """
                                <div style="background-color: #1e293b; padding: 10px; border-radius: 5px; margin-bottom: 20px;">
                                    <p><strong>T√™n file:</strong> {}</p>
                                    <p><strong>T√™n ·ª©ng vi√™n:</strong> {}</p>
                                    <p><strong>M·∫£ng IT:</strong> {}</p>
                                    <p><strong>Ph·∫ßn trƒÉm ph√π h·ª£p:</strong> {}%</p>
                                    <p><strong>K·∫øt qu·∫£:</strong> {}</p>
                                </div>
                                """.format(
                                    selected_file,
                                    extract_name(text),
                                    target_field,
                                    df_show.loc[df_show['T√™n file'] == selected_file, 'Ph·∫ßn trƒÉm ph√π h·ª£p'].values[0],
                                    df_show.loc[df_show['T√™n file'] == selected_file, 'K·∫øt qu·∫£'].values[0]
                                ),
                                unsafe_allow_html=True
                            )

                            present_skills = extract_present_skills(text)
                            st.markdown("### üõ†Ô∏è K·ªπ nƒÉng CV hi·ªán c√≥")
                            st.markdown(
                                "<ul>" + "".join(f"<li>{skill}</li>" for skill in present_skills) + "</ul>"
                                if present_skills else "Kh√¥ng r√µ",
                                unsafe_allow_html=True
                            )

                            candidate_skills = extract_skills_list(text)
                            project_skills = extract_skills_from_projects(text)
                            total_skills = list(set(candidate_skills + project_skills))
                            matched, missing, skill_coverage = match_skills_accurately(total_skills, expected_skills, project_skills)

                            st.markdown("### üìä T·ªâ l·ªá ph√π h·ª£p")
                            st.markdown(f"- **T·ªïng**: {skill_coverage}%")

                            st.markdown("### ‚úÖ K·ªπ nƒÉng ph√π h·ª£p")
                            st.markdown(
                                "<ul>" + "".join(f"<li>{skill}</li>" for skill in matched) + "</ul>"
                                if matched else "Kh√¥ng r√µ",
                                unsafe_allow_html=True
                            )

                            st.markdown("### ‚ùå K·ªπ nƒÉng c√≤n thi·∫øu")
                            st.markdown(
                                "<ul>" + "".join(f"<li>{skill}</li>" for skill in missing) + "</ul>"
                                if missing else "Kh√¥ng r√µ",
                                unsafe_allow_html=True
                            )

                            st.markdown("### üìÇ K·ªπ nƒÉng trong project")
                            st.markdown(
                                "<ul>" + "".join(f"<li>{skill}</li>" for skill in project_skills) + "</ul>"
                                if project_skills else "Kh√¥ng r√µ",
                                unsafe_allow_html=True
                            )

    elif menu == "Dashboard b√°o c√°o":
        st.header("üìä Dashboard B√°o c√°o & Ph√¢n t√≠ch K·∫øt qu·∫£")
        st.markdown("> T·∫£i l√™n file k·∫øt qu·∫£ ph√¢n t√≠ch (CSV) ho·∫∑c s·ª≠ d·ª•ng d·ªØ li·ªáu v·ª´a ph√¢n t√≠ch ƒë·ªÉ xem b√°o c√°o t·ªïng quan.", unsafe_allow_html=True)
        uploaded_csv = st.file_uploader("T·∫£i l√™n file k·∫øt qu·∫£ ph√¢n t√≠ch (CSV)", type="csv")
        df = None
        if uploaded_csv:
            df = pd.read_csv(uploaded_csv)
        elif st.session_state['last_df'] is not None:
            df = st.session_state['last_df']
            st.info("ƒêang d√πng d·ªØ li·ªáu k·∫øt qu·∫£ v·ª´a ph√¢n t√≠ch.")

        if df is not None and not df.empty:
            st.subheader("üìã D·ªØ li·ªáu ph√¢n t√≠ch CV")
            st.dataframe(df)

            total_cv = len(df)
            suitable_cv = len(df[df['K·∫øt qu·∫£'] == "Ph√π h·ª£p"])
            unsuitable_cv = total_cv - suitable_cv
            avg_skill_coverage = df['Ph·∫ßn trƒÉm ph√π h·ª£p'].mean()

            st.subheader("üìä Th·ªëng k√™ t·ªïng quan")
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("T·ªïng s·ªë CV", total_cv)
            col2.metric("S·ªë CV ph√π h·ª£p", suitable_cv)
            col3.metric("S·ªë CV kh√¥ng ph√π h·ª£p", unsuitable_cv)
            col4.metric("T·ªâ l·ªá k·ªπ nƒÉng ph√π h·ª£p TB", f"{avg_skill_coverage:.2f}%")

            st.subheader("üìà Ph√¢n b·ªë t·ªâ l·ªá ph√π h·ª£p")
            fig, ax = plt.subplots(figsize=(8, 4))
            ax.hist(df['Ph·∫ßn trƒÉm ph√π h·ª£p'], bins=10, color='skyblue', edgecolor='black')
            ax.set_title("Ph√¢n b·ªë t·ªâ l·ªá ph√π h·ª£p")
            ax.set_xlabel("T·ªâ l·ªá ph√π h·ª£p (%)")
            ax.set_ylabel("S·ªë l∆∞·ª£ng CV")
            st.pyplot(fig)

            st.subheader("üõ†Ô∏è K·ªπ nƒÉng ph·ªï bi·∫øn trong CV")
            all_skills = []
            for skills in df['K·ªπ nƒÉng hi·ªán c√≥']:
                if isinstance(skills, str):
                    all_skills.extend([s.strip() for s in skills.split(",") if s.strip()])
            skill_counts = Counter(all_skills)
            skill_df = pd.DataFrame(skill_counts.items(), columns=["K·ªπ nƒÉng", "S·ªë l∆∞·ª£ng"]).sort_values(by="S·ªë l∆∞·ª£ng", ascending=False)
            st.bar_chart(skill_df.set_index("K·ªπ nƒÉng"))

            st.subheader("‚ùå K·ªπ nƒÉng c√≤n thi·∫øu ph·ªï bi·∫øn")
            all_missing_skills = []
            for skills in df['K·ªπ nƒÉng c√≤n thi·∫øu']:
                if isinstance(skills, str):
                    all_missing_skills.extend([s.strip() for s in skills.split(",") if s.strip()])
            missing_skill_counts = Counter(all_missing_skills)
            missing_skill_df = pd.DataFrame(missing_skill_counts.items(), columns=["K·ªπ nƒÉng", "S·ªë l∆∞·ª£ng"]).sort_values(by="S·ªë l∆∞·ª£ng", ascending=False)
            st.write(missing_skill_df)

            st.subheader("üì• T·∫£i xu·ªëng d·ªØ li·ªáu")
            csv = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• T·∫£i xu·ªëng file CSV",
                data=csv,
                file_name="ket_qua_phan_tich_cv.csv",
                mime="text/csv"
            )
        else:
            st.info("Vui l√≤ng t·∫£i l√™n file k·∫øt qu·∫£ ho·∫∑c ph√¢n t√≠ch CV tr∆∞·ªõc.")

if __name__ == "__main__":
    main()