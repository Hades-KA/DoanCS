import streamlit as st
import os
st.set_page_config(page_title="H·ªá th·ªëng H·ªó tr·ª£ qu·∫£n l√Ω tuy·ªÉn d·ª•ng ", layout="wide")

# --- Nh√∫ng CSS t·ª´ file style.css ---
with open(os.path.join(os.path.dirname(__file__), "style.css"), encoding="utf-8") as f:
    st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

import pdfplumber
import re
import base64
from transformers import pipeline
import pandas as pd
from concurrent.futures import ThreadPoolExecutor
from rapidfuzz import fuzz
from streamlit_option_menu import option_menu
import unicodedata
import matplotlib.pyplot as plt
from collections import Counter
import plotly.graph_objects as go
# --- Danh s√°ch k·ªπ nƒÉng l·∫≠p tr√¨nh ph·ªï bi·∫øn ---
COMMON_SKILLS = [
    "javascript", "typescript", "reactjs", "redux", "tailwindcss", "java", "spring boot", "spring", "spring framework",
    "spring security", "spring jpa", "validate", "mysql", "sql server", "antd", "cloudinary", "jwt", "php", "vuejs",
    "html", "css", "nodejs", "python", "docker", "kubernetes", "aws", "azure", "flask", "django", "c#", "c++", "android",
    "ios", "react native", "swift", "kotlin"
]

def extract_present_skills(text):
    text_lower = text.lower()
    present_skills = []
    for skill in COMMON_SKILLS:
        if skill in text_lower and skill not in present_skills:
            present_skills.append(skill)
    return present_skills

# üìÖ Th∆∞ m·ª•c l∆∞u CV
UPLOAD_FOLDER = './uploaded_cvs/'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# üìö Load m√¥ h√¨nh AI
@st.cache_resource
def load_classifier():
    try:
        return pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh AI: {str(e)}. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi m·∫°ng ho·∫∑c th·ª≠ l·∫°i sau.")
        return None

classifier = load_classifier()
FIELDS = ["Frontend Development", "Backend Development", "Data Science/AI", "DevOps", "Mobile Development"]

# --- H√†m l∆∞u file ---
def save_uploadedfile(uploadedfile):
    path = os.path.join(UPLOAD_FOLDER, uploadedfile.name)
    with open(path, "wb") as f:
        f.write(uploadedfile.getbuffer())
    return path

# --- H√†m x·ª≠ l√Ω PDF ---
def extract_text_from_pdf(file_path):
    try:
        text = ""
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages[:3]:  # Ch·ªâ ƒë·ªçc 3 trang ƒë·∫ßu
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text.strip()
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file PDF: {str(e)}")
        return ""

# --- Tr√≠ch xu·∫•t t√™n ---
def extract_name(text):
    lines = text.strip().split("\n")
    for line in lines[:10]:
        if re.search(r"(Name|T√™n):", line, re.IGNORECASE):
            return line.split(":")[-1].strip()
    for line in lines[:10]:
        if len(line.split()) >= 2 and line[0].isupper():
            if not any(char.isdigit() for char in line) and len(line.split()) <= 5 and not any(kw in line.lower() for kw in ["contact", "information"]):
                if not any(char.isdigit() for char in line) and len(line.split()) <= 5:
                    return line.strip()
    return "Kh√¥ng r√µ"

# --- Ph√¢n lo·∫°i lƒ©nh v·ª±c, tr·∫£ v·ªÅ c·∫£ score ---
def predict_field(text_cv):
    if classifier is None:
        return "Kh√¥ng x√°c ƒë·ªãnh", 0.0
    short_text = text_cv[:300]
    result = classifier(short_text, candidate_labels=FIELDS)
    return result['labels'][0], result['scores'][0]

# --- Tr√≠ch xu·∫•t k·ªπ nƒÉng t·ª´ CV (d·ª±a tr√™n danh s√°ch ph·ªï bi·∫øn) ---
def extract_skills_list(text):
    text_lower = text.lower()
    skills = []
    for skill in COMMON_SKILLS:
        if skill in text_lower and skill not in skills:
            skills.append(skill)
    return skills

# --- Tr√≠ch xu·∫•t k·ªπ nƒÉng t·ª´ d·ª± √°n (c·∫£i ti·∫øn) ---
def extract_skills_from_projects(text):
    project_skills = set()
    lines = text.split('\n')
    for i, line in enumerate(lines):
        line_lower = line.lower()
        # N·∫øu d√≤ng ch·ª©a t·ª´ kh√≥a k·ªπ nƒÉng
        if any(kw in line_lower for kw in ['tech stack', 'technology', 'tools', 'framework', 's·ª≠ d·ª•ng', 'environment', 'library', 'ng√¥n ng·ªØ']):
            items = re.split(r"[:\-]", line, maxsplit=1)
            if len(items) > 1:
                for skill in re.split(r'[,/‚Ä¢;]', items[1]):
                    skill = skill.strip(" -‚Ä¢()")
                    if 1 < len(skill) <= 40:
                        project_skills.add(skill)
        else:
            # N·∫øu kh√¥ng c√≥ t·ª´ kh√≥a, t√¨m k·ªπ nƒÉng ph·ªï bi·∫øn xu·∫•t hi·ªán trong d√≤ng m√¥ t·∫£ d·ª± √°n
            for skill in COMMON_SKILLS:
                if skill in line_lower:
                    project_skills.add(skill)
    return sorted(project_skills)

# --- Tr√≠ch xu·∫•t t√™n d·ª± √°n (c·∫£i ti·∫øn) ---
def extract_project_names(text):
    project_names = []
    lines = text.split('\n')
    for line in lines:
        line_strip = line.strip()
        # Lo·∫°i b·ªè c√°c ti√™u ƒë·ªÅ l·ªõn
        if re.match(r"^(work|project|experience|notable|personal|projects?)\b", line_strip, re.IGNORECASE):
            continue
        # Nh·∫≠n di·ªán t√™n d·ª± √°n d·∫°ng Project 1: T√™n, Project: T√™n, D·ª± √°n: T√™n, ...
        if re.match(r"^(project\s*\d*|d·ª± √°n|project name|t√™n d·ª± √°n)\s*[:\-]", line_strip, re.IGNORECASE):
            name = re.split(r"[:\-]", line_strip, maxsplit=1)[-1].strip()
            if 3 < len(name) < 80:
                project_names.append(name)
        # Nh·∫≠n di·ªán c√°c d√≤ng c√≥ th·ªÉ l√† t√™n d·ª± √°n (vi·∫øt hoa ƒë·∫ßu, kh√¥ng qu√° d√†i, kh√¥ng c√≥ d·∫•u ch·∫•m c√¢u l·ªõn)
        elif 3 < len(line_strip) < 80 and not any(x in line_strip.lower() for x in ["experience", "project", "work"]) and line_strip[0].isupper():
            project_names.append(line_strip)
    return list(dict.fromkeys(project_names))

# --- So kh·ªõp k·ªπ nƒÉng ---
def normalize_skill(skill):
    skill = unicodedata.normalize('NFKD', skill).encode('ASCII', 'ignore').decode('utf-8')
    return skill.lower().strip()

def match_skills_accurately(candidate_skills, expected_skills, project_skills):
    candidate_skills = list(set(normalize_skill(skill) for skill in candidate_skills))
    expected_skills = list(set(normalize_skill(skill) for skill in expected_skills))
    project_skills = list(set(normalize_skill(skill) for skill in project_skills))

    matched = []
    for expected in expected_skills:
        for candidate in candidate_skills:
            if (
                fuzz.ratio(expected, candidate) >= 50
                or expected in candidate
                or candidate in expected
            ):
                matched.append(expected)
                break

    matched = list(set(matched))
    missing = [s for s in expected_skills if s not in matched]
    missing = [s for s in missing if s not in project_skills]
    missing = list(set(missing))
    coverage = round(len(matched) / len(expected_skills) * 100, 2) if expected_skills else 0
    return matched, missing, coverage

# --- Ki·ªÉm tra lƒ©nh v·ª±c ---
def match_field(text, target_field):
    text = text.lower()
    target_field = target_field.lower()
    field_keywords = {
        "frontend development": ["frontend", "html", "css", "javascript", "react", "angular", "vue"],
        "backend development": ["backend", "node.js", "django", "flask", "spring", "java", "php"],
        "data science/ai": ["data science", "machine learning", "ai", "deep learning", "pandas", "numpy"],
        "devops": ["devops", "docker", "kubernetes", "ci/cd", "aws", "azure", "cloud"],
        "mobile development": ["mobile", "android", "ios", "flutter", "react native", "swift", "kotlin"]
    }
    keywords = field_keywords.get(target_field, [])
    return any(keyword in text for keyword in keywords)

# --- Hi·ªÉn th·ªã file PDF ---
def display_pdf(file_path):
    with open(file_path, "rb") as f:
        base64_pdf = base64.b64encode(f.read()).decode('utf-8')
        pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="700" height="1000" type="application/pdf"></iframe>'
        st.markdown(pdf_display, unsafe_allow_html=True)

# --- Ph√¢n t√≠ch m·ªôt CV ---
def process_cv(file_path, expected_skills, target_field):
    text = extract_text_from_pdf(file_path)
    if text:
        if not match_field(text, target_field):
            return None
        name = extract_name(text)
        candidate_skills = extract_skills_list(text)
        project_skills = extract_skills_from_projects(text)
        project_names = extract_project_names(text)
        total_skills = list(set(candidate_skills + project_skills))
        matched, missing, skill_coverage = match_skills_accurately(total_skills, expected_skills, project_skills)
        present_skills = extract_present_skills(text)
        result_status = "Ph√π h·ª£p" if skill_coverage >= 50 else "Kh√¥ng ph√π h·ª£p"
        return {
            'T√™n file': os.path.basename(file_path),
            'T√™n ·ª©ng vi√™n': name,
            'M·∫£ng IT': target_field,
            'Ph·∫ßn trƒÉm ph√π h·ª£p': skill_coverage,
            'K·∫øt qu·∫£': result_status,
            'K·ªπ nƒÉng hi·ªán c√≥': ', '.join(present_skills),
            'K·ªπ nƒÉng ph√π h·ª£p': ', '.join(matched),
            'K·ªπ nƒÉng c√≤n thi·∫øu': ', '.join(missing),
            'D·ª± √°n trong project': ', '.join(project_names),
            'K·ªπ nƒÉng trong project': ', '.join(project_skills)
        }
    return None

# --- Ph√¢n t√≠ch nhi·ªÅu CV ---
@st.cache_data
def analyze_cvs(uploaded_paths, expected_skills, target_field):
    results = []
    warnings = []
    progress_bar = st.progress(0)
    total_files = len(uploaded_paths)
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(process_cv, path, expected_skills, target_field) for path in uploaded_paths]
        for i, future in enumerate(futures):
            result = future.result()
            if result:
                results.append(result)
            else:
                warnings.append(f"‚ö†Ô∏è CV t·∫°i {uploaded_paths[i]} kh√¥ng ƒë·∫°t ti√™u ch√≠ v√† ƒë√£ b·ªã lo·∫°i b·ªè.")
            progress_bar.progress((i + 1) / total_files)
    if warnings:
        st.warning(f"‚ö†Ô∏è C√≥ {len(warnings)} CV ƒë√£ b·ªã lo·∫°i b·ªè do kh√¥ng ƒë·∫°t ti√™u ch√≠.")
        with st.expander("Xem chi ti·∫øt c√°c c·∫£nh b√°o"):
            st.write("\n".join(warnings))
    return pd.DataFrame(results)

# --- Giao di·ªán ch√≠nh ---
def main():
    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/3135/3135715.png", width=100)
        st.markdown("<div class='sidebar-title'>H·ªá th·ªëng Tuy·ªÉn d·ª•ng AI</div>", unsafe_allow_html=True)
        st.markdown("<div class='sidebar-desc'>T·ªëi ∆∞u h√≥a quy tr√¨nh tuy·ªÉn d·ª•ng, l·ªçc CV ·ª©ng vi√™n t·ª± ƒë·ªông b·∫±ng AI.<br>Ti·∫øt ki·ªám th·ªùi gian, n√¢ng cao hi·ªáu qu·∫£!</div>", unsafe_allow_html=True)
        menu = option_menu(
            None,
            ["Ph√¢n t√≠ch CV", "So s√°nh CV", "Ph·∫ßn trƒÉm ph√π h·ª£p", "Dashboard b√°o c√°o"],
            icons=["file-earmark-text", "files", "bar-chart-line", "bar-chart"],
            menu_icon="cast", default_index=0,
            styles={
                "container": {"padding": "5px", "background-color": "#222"},
                "icon": {"color": "#00d4ff", "font-size": "20px"},
                "nav-link": {"font-size": "16px", "text-align": "left", "margin":"2px", "--hover-color": "#1e90ff"},
                "nav-link-selected": {"background-color": "#1e90ff", "color": "white"},
            }
        )

    st.title("üìÑ H·ªá th·ªëng h·ªó tr·ª£ qu·∫£n l√Ω tuy·ªÉn d·ª•ng ")

    # --- Kh·ªüi t·∫°o session_state ---
    if 'last_df' not in st.session_state:
        st.session_state['last_df'] = None
    if 'uploaded_paths' not in st.session_state:
        st.session_state['uploaded_paths'] = []
    if 'expected_skills' not in st.session_state:
        st.session_state['expected_skills'] = []
    if 'target_field' not in st.session_state:
        st.session_state['target_field'] = ""
    if 'sample_cv_path' not in st.session_state:
        st.session_state['sample_cv_path'] = None
    if 'cv_valid_count' not in st.session_state:
        st.session_state['cv_valid_count'] = 0
    if 'cv_invalid_count' not in st.session_state:
        st.session_state['cv_invalid_count'] = 0
    if 'view_page' not in st.session_state:
        st.session_state['view_page'] = 'phuhop'

    if menu == "Ph√¢n t√≠ch CV":
        st.header("üìÑ Ph√¢n t√≠ch CV")

        # --- X·ª≠ l√Ω upload CV ti√™u ch√≠ ---
        if st.session_state['sample_cv_path']:
            st.success(f"ƒê√£ upload CV ti√™u ch√≠: {os.path.basename(st.session_state['sample_cv_path'])}")
            if st.button("X√≥a CV ti√™u ch√≠"):
                st.session_state['sample_cv_path'] = None
                st.session_state['expected_skills'] = []
                st.session_state['target_field'] = ""
                st.session_state['last_df'] = None
                st.session_state['cv_valid_count'] = 0
                st.session_state['cv_invalid_count'] = 0
        else:
            sample_cv_file = st.file_uploader("üìå T·∫£i l√™n CV ti√™u ch√≠", type="pdf", key="sample_cv_file")
            if sample_cv_file:
                st.session_state['sample_cv_path'] = save_uploadedfile(sample_cv_file)
                sample_cv_text = extract_text_from_pdf(st.session_state['sample_cv_path'])
                st.session_state['expected_skills'] = extract_skills_list(sample_cv_text)
                st.session_state['target_field'], _ = predict_field(sample_cv_text)

        # --- X·ª≠ l√Ω upload c√°c CV ·ª©ng vi√™n ---
        if st.session_state['uploaded_paths']:
            st.success(f"ƒê√£ upload {len(st.session_state['uploaded_paths'])} CV ·ª©ng vi√™n.")
            if st.button("X√≥a t·∫•t c·∫£ CV ·ª©ng vi√™n", key="xoa_cv"):
                st.session_state['uploaded_paths'] = []
                st.session_state['last_df'] = None
                st.session_state['cv_valid_count'] = 0
                st.session_state['cv_invalid_count'] = 0
        else:
            uploaded_files = st.file_uploader("üìÖ T·∫£i l√™n c√°c CV ·ª©ng vi√™n", type=["pdf"], accept_multiple_files=True, key="uploaded_files")
            if uploaded_files:
                st.session_state['uploaded_paths'] = [save_uploadedfile(f) for f in uploaded_files]

        # --- Hi·ªÉn th·ªã l·∫°i th√¥ng b√°o k·∫øt qu·∫£ ---
        if st.session_state['cv_valid_count'] > 0:
            st.success(f"‚úÖ ƒê√£ ph√¢n t√≠ch {st.session_state['cv_valid_count']} CV h·ª£p l·ªá tr√™n t·ªïng s·ªë {st.session_state['cv_valid_count'] + st.session_state['cv_invalid_count']} CV.")
        if st.session_state['cv_invalid_count'] > 0:
            st.warning(f"‚ö†Ô∏è C√≥ {st.session_state['cv_invalid_count']} CV ƒë√£ b·ªã lo·∫°i b·ªè do kh√¥ng ƒë·∫°t ti√™u ch√≠.")

        # --- Ph√¢n t√≠ch khi ƒë·ªß d·ªØ li·ªáu ---
        if st.session_state['sample_cv_path'] and st.session_state['uploaded_paths']:
            if st.button("üöÄ Ph√¢n t√≠ch CV ·ª©ng vi√™n"):
                expected_skills = st.session_state['expected_skills']
                target_field = st.session_state['target_field']
                uploaded_paths = st.session_state['uploaded_paths']

                with st.spinner("üîé ƒêang ti·∫øn h√†nh ph√¢n t√≠ch CV..."):
                    my_bar = st.progress(0)
                    df = analyze_cvs(uploaded_paths, expected_skills, target_field)
                    my_bar.progress(1.0)

                st.session_state['last_df'] = df
                st.session_state['cv_valid_count'] = len(df)
                st.session_state['cv_invalid_count'] = len(uploaded_paths) - len(df)

        # --- Hi·ªÉn th·ªã k·∫øt qu·∫£ n·∫øu ƒë√£ ph√¢n t√≠ch ---
        if st.session_state['last_df'] is not None and len(st.session_state['last_df']) > 0:
            df = st.session_state['last_df']
            uploaded_paths = st.session_state['uploaded_paths']

            col1, col2 = st.columns(2)
            with col1:
                if st.button("üìã Danh s√°ch ·ª©ng vi√™n ph√π h·ª£p"):
                    st.session_state['view_page'] = 'phuhop'
            with col2:
                if st.button("üìã Danh s√°ch ·ª©ng vi√™n kh√¥ng ph√π h·ª£p", key="khongphuhop"):
                    st.session_state['view_page'] = 'khongphuhop'

            if st.session_state['view_page'] == 'phuhop':
                df_show = df[df['K·∫øt qu·∫£'] == "Ph√π h·ª£p"]
                st.subheader(f"‚úÖ Danh s√°ch ·ª©ng vi√™n ph√π h·ª£p ({len(df_show)})")
            else:
                df_show = df[df['K·∫øt qu·∫£'] == "Kh√¥ng ph√π h·ª£p"]
                st.subheader(f"‚ùå Danh s√°ch ·ª©ng vi√™n kh√¥ng ph√π h·ª£p ({len(df_show)})")

            if df_show.empty:
                st.warning("Kh√¥ng c√≥ ·ª©ng vi√™n trong danh s√°ch n√†y.")
            else:
                df_show = df_show.copy()
                df_show.index = range(1, len(df_show) + 1)
                st.dataframe(df_show)

    elif menu == "So s√°nh CV":
        st.header("üîç So s√°nh CV")

        # Ki·ªÉm tra xem ƒë√£ ph√¢n t√≠ch CV ch∆∞a
        if 'last_df' not in st.session_state or st.session_state['last_df'] is None or len(st.session_state['last_df']) == 0:
            st.warning("Vui l√≤ng ph√¢n t√≠ch CV tr∆∞·ªõc t·∫°i m·ª•c 'Ph√¢n t√≠ch CV'!")
        else:
            df = st.session_state['last_df']
            uploaded_paths = st.session_state['uploaded_paths']
            expected_skills = st.session_state['expected_skills']
            target_field = st.session_state['target_field']

            # L·ªçc danh s√°ch CV ph√π h·ª£p (ph·∫ßn trƒÉm ph√π h·ª£p >= 50%)
            suitable_df = df[df['K·∫øt qu·∫£'] == "Ph√π h·ª£p"]

            if len(suitable_df) == 0:
                st.warning("Kh√¥ng c√≥ CV n√†o ph√π h·ª£p ƒë·ªÉ so s√°nh. Vui l√≤ng ki·ªÉm tra l·∫°i k·∫øt qu·∫£ ph√¢n t√≠ch!")
            else:
                # L·ª±a ch·ªçn CV ƒë·ªÉ so s√°nh t·ª´ danh s√°ch CV ph√π h·ª£p
                if 'selected_cvs' not in st.session_state:
                    st.session_state['selected_cvs'] = []

                selected_cvs = st.multiselect(
                    "Ch·ªçn CV ph√π h·ª£p ƒë·ªÉ so s√°nh:",
                    suitable_df['T√™n file'].tolist(),
                    default=st.session_state['selected_cvs']
                )

                st.session_state['selected_cvs'] = selected_cvs

                if len(selected_cvs) < 2:
                    st.info("Vui l√≤ng ch·ªçn √≠t nh·∫•t 2 CV ƒë·ªÉ so s√°nh.")
                else:
                    # T·∫°o b·∫£ng so s√°nh
                    comparison_data = {
                        "Ti√™u ch√≠": [
                            "T√™n ·ª©ng vi√™n",
                            "T√™n file",
                            "M·∫£ng IT",
                            "Ph·∫ßn trƒÉm ph√π h·ª£p",
                            "K·∫øt qu·∫£",
                            "K·ªπ nƒÉng ph√π h·ª£p",
                            "K·ªπ nƒÉng c√≤n thi·∫øu",
                            "K·ªπ nƒÉng trong project"
                        ]
                    }

                    # L·∫•y th√¥ng tin chi ti·∫øt c·ªßa t·ª´ng CV
                    cv_details = []
                    for selected_file in selected_cvs:
                        selected_path = next((path for path in uploaded_paths if os.path.basename(path) == selected_file), None)
                        if selected_path:
                            text = extract_text_from_pdf(selected_path)
                            if text:
                                candidate_name = extract_name(text)
                                candidate_skills = extract_skills_list(text)
                                project_skills = extract_skills_from_projects(text)
                                project_names = extract_project_names(text)
                                matched, missing, skill_coverage = match_skills_accurately(candidate_skills + project_skills, expected_skills, project_skills)
                                result = df.loc[df['T√™n file'] == selected_file].iloc[0]

                                cv_details.append({
                                    'T√™n file': selected_file,
                                    'T√™n ·ª©ng vi√™n': candidate_name,
                                    'M·∫£ng IT': result['M·∫£ng IT'],
                                    'Ph·∫ßn trƒÉm ph√π h·ª£p': result['Ph·∫ßn trƒÉm ph√π h·ª£p'],
                                    'Ph·∫ßn trƒÉm ph√π h·ª£p_raw': f"{result['Ph·∫ßn trƒÉm ph√π h·ª£p']}%",
                                    'K·∫øt qu·∫£': result['K·∫øt qu·∫£'],
                                    'K·ªπ nƒÉng ph√π h·ª£p': ', '.join(matched) if matched else 'Kh√¥ng r√µ',
                                    'K·ªπ nƒÉng c√≤n thi·∫øu': ', '.join(missing) if missing else 'Kh√¥ng r√µ',
                                    'K·ªπ nƒÉng trong project': ', '.join(project_skills) if project_skills else 'Kh√¥ng r√µ',
                                    'Path': selected_path
                                })

                    # ƒêi·ªÅn d·ªØ li·ªáu v√†o b·∫£ng so s√°nh v·ªõi highlight
                    for i, cv in enumerate(cv_details):
                        # Highlight Ph·∫ßn trƒÉm ph√π h·ª£p
                        percentage = cv['Ph·∫ßn trƒÉm ph√π h·ª£p']
                        percentage_str = cv['Ph·∫ßn trƒÉm ph√π h·ª£p_raw']
                        if percentage >= 50:
                            percentage_str = f"<div class='percentage-tooltip'><span class='highlight-suitable'>{percentage_str}</span><span class='tooltiptext'>T·ªâ l·ªá k·ªπ nƒÉng ph√π h·ª£p v·ªõi y√™u c·∫ßu c√¥ng vi·ªác</span></div>"
                        else:
                            percentage_str = f"<div class='percentage-tooltip'><span class='highlight-unsuitable'>{percentage_str}</span><span class='tooltiptext'>T·ªâ l·ªá k·ªπ nƒÉng ph√π h·ª£p v·ªõi y√™u c·∫ßu c√¥ng vi·ªác</span></div>"

                        # Highlight K·∫øt qu·∫£
                        result = cv['K·∫øt qu·∫£']
                        if result == "Ph√π h·ª£p":
                            result = f"<span class='highlight-suitable'>{result}</span>"
                        else:
                            result = f"<span class='highlight-unsuitable'>{result}</span>"

                        # Highlight K·ªπ nƒÉng ph√π h·ª£p
                        matched_skills = cv['K·ªπ nƒÉng ph√π h·ª£p']
                        if matched_skills != "Kh√¥ng r√µ":
                            matched_skills = f"<span class='highlight-skills-matched'>{matched_skills}</span>"

                        # Highlight K·ªπ nƒÉng c√≤n thi·∫øu
                        missing_skills = cv['K·ªπ nƒÉng c√≤n thi·∫øu']
                        if missing_skills != "Kh√¥ng r√µ":
                            missing_skills = f"<span class='highlight-skills-missing'>{missing_skills}</span>"

                        comparison_data[f"CV {i+1}"] = [
                            cv['T√™n ·ª©ng vi√™n'],
                            cv['T√™n file'],
                            cv['M·∫£ng IT'],
                            percentage_str,
                            result,
                            matched_skills,
                            missing_skills,
                            cv['K·ªπ nƒÉng trong project']
                        ]

                    # Hi·ªÉn th·ªã b·∫£ng so s√°nh
                    comparison_df = pd.DataFrame(comparison_data)

                    # H√†m x·ª≠ l√Ω x√≥a CV
                    def remove_cv(index):
                        if 0 <= index < len(st.session_state['selected_cvs']):
                            st.session_state['selected_cvs'].pop(index)
                        st.rerun()  # S·ª≠ d·ª•ng st.rerun() thay v√¨ st.experimental_rerun()

                    # Th√™m n√∫t "X√≥a" cho t·ª´ng CV
                    st.subheader("üìä B·∫£ng so s√°nh CV")
                    cols = st.columns([1] + [3] * len(selected_cvs))
                    with cols[0]:
                        st.write("")  # C·ªôt ƒë·∫ßu ti√™n ƒë·ªÉ tr·ªëng cho ti√™u ch√≠
                    for i, (cv, col) in enumerate(zip(cv_details, cols[1:])):
                        with col:
                            st.write(f"**CV {i+1}: {cv['T√™n ·ª©ng vi√™n']}**")
                            if st.button(f"X√≥a CV {i+1}", key=f"remove_cv_{i}", help=f"X√≥a CV {cv['T√™n ·ª©ng vi√™n']} kh·ªèi b·∫£ng so s√°nh", on_click=lambda x=i: remove_cv(x)):
                                pass  # Logic x√≥a ƒë∆∞·ª£c x·ª≠ l√Ω trong remove_cv

                    # Th√™m class CSS cho b·∫£ng
                    html_table = comparison_df.set_index("Ti√™u ch√≠").to_html(escape=False, classes="comparison-table")
                    st.markdown(html_table, unsafe_allow_html=True)

                    # Hi·ªÉn th·ªã CV g·ªëc
                    st.subheader("üìÑ CV g·ªëc c·ªßa c√°c ·ª©ng vi√™n")
                    for cv in cv_details:
                        with st.expander(f"Xem CV g·ªëc: {cv['T√™n ·ª©ng vi√™n']} ({cv['T√™n file']})"):
                            display_pdf(cv['Path'])

    elif menu == "Ph·∫ßn trƒÉm ph√π h·ª£p":
        st.header("üìä Ph·∫ßn trƒÉm ph√π h·ª£p")

        # Ki·ªÉm tra xem ƒë√£ ph√¢n t√≠ch CV ch∆∞a
        if 'last_df' not in st.session_state or st.session_state['last_df'] is None or len(st.session_state['last_df']) == 0:
            st.warning("Vui l√≤ng ph√¢n t√≠ch CV tr∆∞·ªõc t·∫°i m·ª•c 'Ph√¢n t√≠ch CV'!")
        else:
            df = st.session_state['last_df']

            # L·ªçc danh s√°ch CV ph√π h·ª£p (ph·∫ßn trƒÉm ph√π h·ª£p >= 50%)
            suitable_df = df[df['K·∫øt qu·∫£'] == "Ph√π h·ª£p"]

            if len(suitable_df) == 0:
                st.warning("Kh√¥ng c√≥ CV n√†o ph√π h·ª£p ƒë·ªÉ so s√°nh. Vui l√≤ng ki·ªÉm tra l·∫°i k·∫øt qu·∫£ ph√¢n t√≠ch!")
            else:
                # L·ª±a ch·ªçn nhi·ªÅu CV ƒë·ªÉ so s√°nh t·ª´ danh s√°ch CV ph√π h·ª£p
                selected_files = st.multiselect("Ch·ªçn c√°c CV ph√π h·ª£p ƒë·ªÉ xem t·ª∑ l·ªá ph·∫ßn trƒÉm:", suitable_df['T√™n file'].tolist(), default=suitable_df['T√™n file'].tolist()[:2], max_selections=5)

                if len(selected_files) < 1:
                    st.info("Vui l√≤ng ch·ªçn √≠t nh·∫•t 1 CV ƒë·ªÉ xem bi·ªÉu ƒë·ªì.")
                else:
                    # T·∫°o DataFrame ch·ª©a c√°c CV ƒë∆∞·ª£c ch·ªçn
                    comparison_df = suitable_df[suitable_df['T√™n file'].isin(selected_files)][['T√™n ·ª©ng vi√™n', 'Ph·∫ßn trƒÉm ph√π h·ª£p']]
                    comparison_df = comparison_df.reset_index(drop=True)
                    comparison_df.index = range(1, len(comparison_df) + 1)

                    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì c·ªôt b·∫±ng Plotly
                    st.subheader("üìà So s√°nh ph·∫ßn trƒÉm ph√π h·ª£p")
                    fig = go.Figure(data=
                        go.Bar(
                            x=comparison_df['T√™n ·ª©ng vi√™n'],
                            y=comparison_df['Ph·∫ßn trƒÉm ph√π h·ª£p'],
                            marker_color=['#00d4ff', '#1e90ff', '#00b7eb', '#007bff', '#00aaff'][:len(selected_files)],
                            text=comparison_df['Ph·∫ßn trƒÉm ph√π h·ª£p'],
                            textposition='auto'
                        )
                    )
                    fig.update_layout(
                        title='So s√°nh ph·∫ßn trƒÉm ph√π h·ª£p',
                        xaxis_title="T√™n ·ª©ng vi√™n",
                        yaxis_title="Ph·∫ßn trƒÉm ph√π h·ª£p (%)",
                        yaxis_range=[0, 100],
                        plot_bgcolor='#181c24',
                        paper_bgcolor='#181c24',
                        font_color='#00d4ff'
                    )
                    st.plotly_chart(fig)

    elif menu == "Dashboard b√°o c√°o":
        st.header("üìä Dashboard B√°o c√°o & Ph√¢n t√≠ch K·∫øt qu·∫£")
        st.markdown("> T·∫£i l√™n file k·∫øt qu·∫£ ph√¢n t√≠ch (CSV) ho·∫∑c s·ª≠ d·ª•ng d·ªØ li·ªáu v·ª´a ph√¢n t√≠ch ƒë·ªÉ xem b√°o c√°o t·ªïng quan.", unsafe_allow_html=True)
        uploaded_csv = st.file_uploader("T·∫£i l√™n file k·∫øt qu·∫£ ph√¢n t√≠ch (CSV)", type="csv")
        df = None
        if uploaded_csv:
            df = pd.read_csv(uploaded_csv)
        elif st.session_state['last_df'] is not None:
            df = st.session_state['last_df']
            st.info("ƒêang d√πng d·ªØ li·ªáu k·∫øt qu·∫£ v·ª´a ph√¢n t√≠ch.")

        if df is not None and not df.empty:
            st.subheader("üìã D·ªØ li·ªáu ph√¢n t√≠ch CV")
            st.dataframe(df)

            total_cv = len(df)
            suitable_cv = len(df[df['K·∫øt qu·∫£'] == "Ph√π h·ª£p"])
            unsuitable_cv = total_cv - suitable_cv
            avg_skill_coverage = df['Ph·∫ßn trƒÉm ph√π h·ª£p'].mean()

            st.subheader("üìä Th·ªëng k√™ t·ªïng quan")
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("T·ªïng s·ªë CV", total_cv)
            col2.metric("S·ªë CV ph√π h·ª£p", suitable_cv)
            col3.metric("S·ªë CV kh√¥ng ph√π h·ª£p", unsuitable_cv)
            col4.metric("T·ªâ l·ªá k·ªπ nƒÉng ph√π h·ª£p TB", f"{avg_skill_coverage:.2f}%")

            st.subheader("üìà Ph√¢n b·ªë t·ªâ l·ªá ph√π h·ª£p")
            fig, ax = plt.subplots(figsize=(8, 4))
            ax.hist(df['Ph·∫ßn trƒÉm ph√π h·ª£p'], bins=10, color='skyblue', edgecolor='black')
            ax.set_title("Ph√¢n b·ªë t·ªâ l·ªá ph√π h·ª£p")
            ax.set_xlabel("T·ªâ l·ªá ph√π h·ª£p (%)")
            ax.set_ylabel("S·ªë l∆∞·ª£ng CV")
            st.pyplot(fig)

            st.subheader("üõ†Ô∏è K·ªπ nƒÉng ph·ªï bi·∫øn trong CV")
            all_skills = []
            for skills in df['K·ªπ nƒÉng hi·ªán c√≥']:
                if isinstance(skills, str):
                    all_skills.extend([s.strip() for s in skills.split(",") if s.strip()])
            skill_counts = Counter(all_skills)
            skill_df = pd.DataFrame(skill_counts.items(), columns=["K·ªπ nƒÉng", "S·ªë l∆∞·ª£ng"]).sort_values(by="S·ªë l∆∞·ª£ng", ascending=False)
            st.bar_chart(skill_df.set_index("K·ªπ nƒÉng"))

            st.subheader("‚ùå K·ªπ nƒÉng c√≤n thi·∫øu ph·ªï bi·∫øn")
            all_missing_skills = []
            for skills in df['K·ªπ nƒÉng c√≤n thi·∫øu']:
                if isinstance(skills, str):
                    all_missing_skills.extend([s.strip() for s in skills.split(",") if s.strip()])
            missing_skill_counts = Counter(all_missing_skills)
            missing_skill_df = pd.DataFrame(missing_skill_counts.items(), columns=["K·ªπ nƒÉng", "S·ªë l∆∞·ª£ng"]).sort_values(by="S·ªë l∆∞·ª£ng", ascending=False)
            st.write(missing_skill_df)

            st.subheader("üì• T·∫£i xu·ªëng d·ªØ li·ªáu")
            csv = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• T·∫£i xu·ªëng file CSV",
                data=csv,
                file_name="ket_qua_phan_tich_cv.csv",
                mime="text/csv"
            )
        else:
            st.info("Vui l√≤ng t·∫£i l√™n file k·∫øt qu·∫£ ho·∫∑c ph√¢n t√≠ch CV tr∆∞·ªõc.")

if __name__ == "__main__":
    main()