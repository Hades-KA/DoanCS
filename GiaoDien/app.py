# üì¶ Import th∆∞ vi·ªán
import streamlit as st
st.set_page_config(page_title="H·ªá th·ªëng H·ªó tr·ª£ Tuy·ªÉn d·ª•ng b·∫±ng AI", layout="wide")

import os
import pdfplumber
import re
import base64
from transformers import pipeline
import pandas as pd
from concurrent.futures import ThreadPoolExecutor
from rapidfuzz import fuzz
from streamlit_option_menu import option_menu
import unicodedata

# --- Danh s√°ch k·ªπ nƒÉng l·∫≠p tr√¨nh ph·ªï bi·∫øn ---
COMMON_SKILLS = [
    "javascript", "typescript", "reactjs", "redux", "tailwindcss", "java", "spring boot", "spring", "spring framework",
    "spring security", "spring jpa", "validate", "mysql", "sql server", "antd", "cloudinary", "jwt", "php", "vuejs",
    "html", "css", "nodejs", "python", "docker", "kubernetes", "aws", "azure", "flask", "django", "c#", "c++", "android",
    "ios", "react native", "swift", "kotlin"
]

def extract_present_skills(text):
    text_lower = text.lower()
    present_skills = []
    for skill in COMMON_SKILLS:
        if skill in text_lower and skill not in present_skills:
            present_skills.append(skill)
    return present_skills

# --- CSS tu·ª≥ ch·ªânh ---
st.markdown("""
    <style>
    .stApp { background-color: #181c24; }
    .css-1d391kg, .css-1v0mbdj, .css-1cypcdb { color: #00d4ff !important; }
    .stSidebar { background: #23272f; }
    .sidebar-title { color: #00d4ff; font-size: 22px; font-weight: bold; text-align: center; }
    .sidebar-desc { color: #aaa; font-size: 14px; text-align: center; }
    .stButton>button, .stDownloadButton>button { background: linear-gradient(90deg,#00d4ff,#1e90ff); color: white; }
    .stDataFrame { background-color: #23272f; }
    .metric-label, .metric-value { color: #00d4ff !important; }
    .stProgress > div > div > div > div { background-image: linear-gradient(90deg,#00d4ff,#1e90ff); }
    </style>
""", unsafe_allow_html=True)

# üìÖ Th∆∞ m·ª•c l∆∞u CV
UPLOAD_FOLDER = './uploaded_cvs/'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# üìö Load m√¥ h√¨nh AI
@st.cache_resource
def load_classifier():
    try:
        return pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh AI: {str(e)}. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi m·∫°ng ho·∫∑c th·ª≠ l·∫°i sau.")
        return None

classifier = load_classifier()
FIELDS = ["Frontend Development", "Backend Development", "Data Science/AI", "DevOps", "Mobile Development"]

# --- H√†m l∆∞u file ---
def save_uploadedfile(uploadedfile):
    path = os.path.join(UPLOAD_FOLDER, uploadedfile.name)
    with open(path, "wb") as f:
        f.write(uploadedfile.getbuffer())
    return path

# --- H√†m x·ª≠ l√Ω PDF ---
def extract_text_from_pdf(file_path):
    try:
        text = ""
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages[:3]:  # Ch·ªâ ƒë·ªçc 3 trang ƒë·∫ßu
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text.strip()
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file PDF: {str(e)}")
        return ""

# --- Tr√≠ch xu·∫•t t√™n ---
def extract_name(text):
    lines = text.strip().split("\n")
    for line in lines[:30]:
        if re.search(r"(Name|T√™n):", line, re.IGNORECASE):
            return line.split(":")[-1].strip()
    for line in lines[:30]:
        if len(line.split()) >= 2 and line[0].isupper():
            if not any(char.isdigit() for char in line) and len(line.split()) <= 5:
                return line.strip()
    return "Kh√¥ng r√µ"

# --- Ph√¢n lo·∫°i lƒ©nh v·ª±c ---
def predict_field(text_cv):
    if classifier is None:
        return "Kh√¥ng x√°c ƒë·ªãnh"
    short_text = text_cv[:300]
    result = classifier(short_text, candidate_labels=FIELDS)
    return result['labels'][0]

# --- Tr√≠ch xu·∫•t k·ªπ nƒÉng t·ª´ CV (d·ª±a tr√™n danh s√°ch ph·ªï bi·∫øn) ---
def extract_skills_list(text):
    text_lower = text.lower()
    skills = []
    for skill in COMMON_SKILLS:
        if skill in text_lower and skill not in skills:
            skills.append(skill)
    return skills

# --- Tr√≠ch xu·∫•t k·ªπ nƒÉng t·ª´ d·ª± √°n ---
def extract_skills_from_projects(text):
    sections = re.findall(r"(?i)(project|d·ª± √°n)[^\n]*\n+(.*?)(?=\n{2,}|\Z)", text, re.DOTALL)
    all_skills = set()
    for _, section in sections:
        lines = section.split('\n')
        for line in lines:
            if any(kw in line.lower() for kw in ['stack', 'tech', 'technology', 'tools', 'framework', 's·ª≠ d·ª•ng']):
                items = re.split(r'[:,]', line)
                if len(items) > 1:
                    for part in re.split(r'[,/‚Ä¢]', items[1]):
                        skill = part.strip(" -‚Ä¢()")
                        if 1 < len(skill) <= 30:
                            all_skills.add(skill)
    return sorted(all_skills)

# --- So kh·ªõp k·ªπ nƒÉng ---
def normalize_skill(skill):
    skill = unicodedata.normalize('NFKD', skill).encode('ASCII', 'ignore').decode('utf-8')
    return skill.lower().strip()

def match_skills_accurately(candidate_skills, expected_skills, project_skills):
    candidate_skills = list(set(normalize_skill(skill) for skill in candidate_skills))
    expected_skills = list(set(normalize_skill(skill) for skill in expected_skills))
    project_skills = list(set(normalize_skill(skill) for skill in project_skills))

    matched = []
    for expected in expected_skills:
        for candidate in candidate_skills:
            if (
                fuzz.ratio(expected, candidate) >= 50
                or expected in candidate
                or candidate in expected
            ):
                matched.append(expected)
                break

    matched = list(set(matched))
    missing = [s for s in expected_skills if s not in matched]
    missing = [s for s in missing if s not in project_skills]
    missing = list(set(missing))
    coverage = round(len(matched) / len(expected_skills) * 100, 2) if expected_skills else 0
    return matched, missing, coverage

# --- Ki·ªÉm tra lƒ©nh v·ª±c ---
def match_field(text, target_field):
    text = text.lower()
    target_field = target_field.lower()
    field_keywords = {
        "frontend development": ["frontend", "html", "css", "javascript", "react", "angular", "vue"],
        "backend development": ["backend", "node.js", "django", "flask", "spring", "java", "php"],
        "data science/ai": ["data science", "machine learning", "ai", "deep learning", "pandas", "numpy"],
        "devops": ["devops", "docker", "kubernetes", "ci/cd", "aws", "azure", "cloud"],
        "mobile development": ["mobile", "android", "ios", "flutter", "react native", "swift", "kotlin"]
    }
    keywords = field_keywords.get(target_field, [])
    return any(keyword in text for keyword in keywords)

# --- Hi·ªÉn th·ªã file PDF ---
def display_pdf(file_path):
    with open(file_path, "rb") as f:
        base64_pdf = base64.b64encode(f.read()).decode('utf-8')
        pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="700" height="1000" type="application/pdf"></iframe>'
        st.markdown(pdf_display, unsafe_allow_html=True)

# --- Ph√¢n t√≠ch m·ªôt CV ---
def process_cv(file_path, expected_skills, target_field):
    text = extract_text_from_pdf(file_path)
    if text:
        if not match_field(text, target_field):
            return None
        name = extract_name(text)
        candidate_skills = extract_skills_list(text)
        project_skills = extract_skills_from_projects(text)
        total_skills = list(set(candidate_skills + project_skills))
        matched, missing, skill_coverage = match_skills_accurately(total_skills, expected_skills, project_skills)
        present_skills = extract_present_skills(text)
        result_status = "Ph√π h·ª£p" if skill_coverage >= 50 else "Kh√¥ng ph√π h·ª£p"
        return {
            'T√™n file': os.path.basename(file_path),
            'T√™n ·ª©ng vi√™n': name,
            'M·∫£ng IT': target_field,
            'Ph·∫ßn trƒÉm ph√π h·ª£p': skill_coverage,
            'K·∫øt qu·∫£': result_status,
            'K·ªπ nƒÉng hi·ªán c√≥': ', '.join(present_skills),
            'K·ªπ nƒÉng ph√π h·ª£p': ', '.join(matched),
            'K·ªπ nƒÉng c√≤n thi·∫øu': ', '.join(missing),
            'K·ªπ nƒÉng trong project': ', '.join(project_skills)
        }
    return None

# --- Ph√¢n t√≠ch nhi·ªÅu CV ---
@st.cache_data
def analyze_cvs(uploaded_paths, expected_skills, target_field):
    results = []
    warnings = []
    progress_bar = st.progress(0)
    total_files = len(uploaded_paths)
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(process_cv, path, expected_skills, target_field) for path in uploaded_paths]
        for i, future in enumerate(futures):
            result = future.result()
            if result:
                results.append(result)
            else:
                warnings.append(f"‚ö†Ô∏è CV t·∫°i {uploaded_paths[i]} kh√¥ng ƒë·∫°t ti√™u ch√≠ v√† ƒë√£ b·ªã lo·∫°i b·ªè.")
            progress_bar.progress((i + 1) / total_files)
    if warnings:
        st.warning(f"‚ö†Ô∏è C√≥ {len(warnings)} CV ƒë√£ b·ªã lo·∫°i b·ªè do kh√¥ng ƒë·∫°t ti√™u ch√≠.")
        with st.expander("Xem chi ti·∫øt c√°c c·∫£nh b√°o"):
            st.write("\n".join(warnings))
    return pd.DataFrame(results)

# --- Giao di·ªán ch√≠nh ---
def main():
    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/3135/3135715.png", width=100)
        st.markdown("<div class='sidebar-title'>H·ªá th·ªëng Tuy·ªÉn d·ª•ng AI</div>", unsafe_allow_html=True)
        st.markdown("<div class='sidebar-desc'>T·ªëi ∆∞u h√≥a quy tr√¨nh tuy·ªÉn d·ª•ng, l·ªçc CV ·ª©ng vi√™n t·ª± ƒë·ªông b·∫±ng AI.<br>Ti·∫øt ki·ªám th·ªùi gian, n√¢ng cao hi·ªáu qu·∫£!</div>", unsafe_allow_html=True)
        menu = option_menu(
            None,
            ["Ph√¢n t√≠ch CV", "Dashboard b√°o c√°o"],
            icons=["file-earmark-text", "bar-chart"],
            menu_icon="cast", default_index=0,
            styles={
                "container": {"padding": "5px", "background-color": "#222"},
                "icon": {"color": "#00d4ff", "font-size": "20px"},
                "nav-link": {"font-size": "16px", "text-align": "left", "margin":"2px", "--hover-color": "#1e90ff"},
                "nav-link-selected": {"background-color": "#1e90ff", "color": "white"},
            }
        )

    st.title("üìÑ H·ªá th·ªëng H·ªó tr·ª£ Qu·∫£n l√Ω Tuy·ªÉn d·ª•ng b·∫±ng AI")

    if menu == "Ph√¢n t√≠ch CV":
        st.header("üìÑ Ph√¢n t√≠ch CV")
        sample_cv_file = st.file_uploader("üìå T·∫£i l√™n CV ti√™u ch√≠", type="pdf")
        uploaded_files = st.file_uploader("üìÖ T·∫£i l√™n c√°c CV ·ª©ng vi√™n", type=["pdf"], accept_multiple_files=True)

        if sample_cv_file and uploaded_files:
            sample_cv_path = save_uploadedfile(sample_cv_file)
            sample_cv_text = extract_text_from_pdf(sample_cv_path)
            expected_skills = extract_skills_list(sample_cv_text)
            target_field = predict_field(sample_cv_text)

            uploaded_paths = [save_uploadedfile(uploaded_file) for uploaded_file in uploaded_files]
            st.success(f"‚úÖ ƒê√£ upload {len(uploaded_files)} CV ·ª©ng vi√™n.")

            with st.spinner("üîé ƒêang ti·∫øn h√†nh ph√¢n t√≠ch CV..."):
                my_bar = st.progress(0)
                df = analyze_cvs(uploaded_paths, expected_skills, target_field)
                my_bar.progress(1.0)

            st.subheader("üìä T√≥m t·∫Øt k·∫øt qu·∫£")
            st.success(f"‚úÖ ƒê√£ ph√¢n t√≠ch {len(df)} CV h·ª£p l·ªá tr√™n t·ªïng s·ªë {len(uploaded_files)} CV.")

            if df.empty:
                st.warning("‚ö†Ô∏è Kh√¥ng c√≥ CV n√†o ph√π h·ª£p v·ªõi ti√™u ch√≠.")
            else:
                st.subheader("üìã Danh s√°ch ·ª©ng vi√™n ph√π h·ª£p")
                df.index = df.index + 1
                st.dataframe(df)

                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üìÖ T·∫£i danh s√°ch ·ª©ng vi√™n ƒë√£ ƒë√°nh gi√°",
                    data=csv,
                    file_name='cv_filtered_results.csv',
                    mime='text/csv',
                )

                st.subheader("üîç Xem chi ti·∫øt t·ª´ng CV")
                selected_file = st.selectbox("Ch·ªçn m·ªôt file CV ƒë·ªÉ xem chi ti·∫øt:", df['T√™n file'].tolist())


                if selected_file:
                    selected_path = next((path for path in uploaded_paths if os.path.basename(path) == selected_file), None)
                    if selected_path:
                        text = extract_text_from_pdf(selected_path)
                        if text:
                            st.markdown(f"### üìÑ Ph√¢n t√≠ch chi ti·∫øt CV: `{selected_file}`")
                            display_pdf(selected_path)  # Hi·ªÉn th·ªã PDF ngay sau th√¥ng tin c∆° b·∫£n

                            # Th√¥ng tin c∆° b·∫£n
                            st.markdown(
                                """
                                <div style="background-color: #1e293b; padding: 10px; border-radius: 5px; margin-bottom: 20px;">
                                    <p><strong>T√™n file:</strong> {}</p>
                                    <p><strong>T√™n ·ª©ng vi√™n:</strong> {}</p>
                                    <p><strong>M·∫£ng IT:</strong> {}</p>
                                    <p><strong>Ph·∫ßn trƒÉm ph√π h·ª£p:</strong> {}%</p>
                                    <p><strong>K·∫øt qu·∫£:</strong> {}</p>
                                </div>
                                """.format(
                                    selected_file,
                                    extract_name(text),
                                    target_field,
                                    df.loc[df['T√™n file'] == selected_file, 'Ph·∫ßn trƒÉm ph√π h·ª£p'].values[0],
                                    df.loc[df['T√™n file'] == selected_file, 'K·∫øt qu·∫£'].values[0]
                                ),
                                unsafe_allow_html=True
                            )

                            # K·ªπ nƒÉng hi·ªán c√≥
                            present_skills = extract_present_skills(text)
                            st.markdown("### üõ†Ô∏è K·ªπ nƒÉng CV hi·ªán c√≥")
                            st.markdown(
                                "<ul>" + "".join(f"<li>{skill}</li>" for skill in present_skills) + "</ul>"
                                if present_skills else "Kh√¥ng r√µ",
                                unsafe_allow_html=True
                            )

                            # K·ªπ nƒÉng ph√π h·ª£p, c√≤n thi·∫øu, trong project
                            candidate_skills = extract_skills_list(text)
                            project_skills = extract_skills_from_projects(text)
                            total_skills = list(set(candidate_skills + project_skills))
                            matched, missing, skill_coverage = match_skills_accurately(total_skills, expected_skills, project_skills)

                            st.markdown("### üìä T·ªâ l·ªá ph√π h·ª£p")
                            st.markdown(f"- **T·ªïng**: {skill_coverage}%")

                            st.markdown("### ‚úÖ K·ªπ nƒÉng ph√π h·ª£p")
                            st.markdown(
                                "<ul>" + "".join(f"<li>{skill}</li>" for skill in matched) + "</ul>"
                                if matched else "Kh√¥ng r√µ",
                                unsafe_allow_html=True
                            )

                            st.markdown("### ‚ùå K·ªπ nƒÉng c√≤n thi·∫øu")
                            st.markdown(
                                "<ul>" + "".join(f"<li>{skill}</li>" for skill in missing) + "</ul>"
                                if missing else "Kh√¥ng r√µ",
                                unsafe_allow_html=True
                            )

                            st.markdown("### üìÇ K·ªπ nƒÉng trong project")
                            st.markdown(
                                "<ul>" + "".join(f"<li>{skill}</li>" for skill in project_skills) + "</ul>"
                                if project_skills else "Kh√¥ng r√µ",
                                unsafe_allow_html=True
                            )


            st.session_state['last_df'] = df

    elif menu == "Dashboard b√°o c√°o":
        st.header("üìä Dashboard B√°o c√°o & Ph√¢n t√≠ch K·∫øt qu·∫£")
        st.markdown("> T·∫£i l√™n file k·∫øt qu·∫£ ph√¢n t√≠ch (CSV) ho·∫∑c s·ª≠ d·ª•ng d·ªØ li·ªáu v·ª´a ph√¢n t√≠ch ƒë·ªÉ xem b√°o c√°o t·ªïng quan.", unsafe_allow_html=True)
        uploaded_csv = st.file_uploader("T·∫£i l√™n file k·∫øt qu·∫£ ph√¢n t√≠ch (CSV)", type="csv")
        df = None
        if uploaded_csv:
            df = pd.read_csv(uploaded_csv)
        elif 'last_df' in st.session_state:
            df = st.session_state['last_df']
            st.info("ƒêang d√πng d·ªØ li·ªáu k·∫øt qu·∫£ v·ª´a ph√¢n t√≠ch.")
        if df is not None and not df.empty:
            st.dataframe(df)
        else:
            st.info("Vui l√≤ng t·∫£i l√™n file k·∫øt qu·∫£ ho·∫∑c ph√¢n t√≠ch CV tr∆∞·ªõc.")

if __name__ == "__main__":
    main()