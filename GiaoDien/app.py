# ğŸ“¦ Import thÆ° viá»‡n
import streamlit as st
st.set_page_config(page_title="Há»‡ thá»‘ng Há»— trá»£ Tuyá»ƒn dá»¥ng báº±ng AI", layout="wide")

import os
import pdfplumber
import re
import base64
from transformers import pipeline
import pandas as pd
from concurrent.futures import ThreadPoolExecutor
import matplotlib.pyplot as plt
from collections import Counter
from streamlit_option_menu import option_menu

# --- CSS tuá»³ chá»‰nh cho giao diá»‡n Ä‘áº¹p hÆ¡n ---
st.markdown("""
    <style>
    .stApp {
        background-color: #181c24;
    }
    .css-1d391kg, .css-1v0mbdj, .css-1cypcdb {
        color: #00d4ff !important;
    }
    .stSidebar {
        background: #23272f;
    }
    .sidebar-title {
        color: #00d4ff;
        font-size: 22px;
        font-weight: bold;
        margin-bottom: 0px;
        margin-top: 10px;
        text-align: center;
        letter-spacing: 1px;
    }
    .sidebar-desc {
        color: #aaa;
        font-size: 14px;
        text-align: center;
        margin-bottom: 20px;
    }
    .stButton>button {
        background: linear-gradient(90deg,#00d4ff,#1e90ff);
        color: white;
        border-radius: 8px;
        border: none;
        font-weight: bold;
    }
    .stDownloadButton>button {
        background: linear-gradient(90deg,#00d4ff,#1e90ff);
        color: white;
        border-radius: 8px;
        border: none;
        font-weight: bold;
    }
    .stDataFrame {
        background-color: #23272f;
    }
    .metric-label, .metric-value {
        color: #00d4ff !important;
    }
    .stProgress > div > div > div > div {
        background-image: linear-gradient(90deg,#00d4ff,#1e90ff);
    }
    </style>
""", unsafe_allow_html=True)

# ğŸ“… ThÆ° má»¥c lÆ°u CV
UPLOAD_FOLDER = './uploaded_cvs/'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# ğŸ“š Load mÃ´ hÃ¬nh AI
@st.cache_resource
def load_classifier():
    try:
        return pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
    except Exception as e:
        st.error(f"Lá»—i khi táº£i mÃ´ hÃ¬nh AI: {str(e)}. Vui lÃ²ng kiá»ƒm tra káº¿ ná»‘i máº¡ng hoáº·c thá»­ láº¡i sau.")
        return None

classifier = load_classifier()
FIELDS = ["Frontend Development", "Backend Development", "Data Science/AI", "DevOps", "Mobile Development"]

# --- HÃ m lÆ°u file ---
def save_uploadedfile(uploadedfile):
    path = os.path.join(UPLOAD_FOLDER, uploadedfile.name)
    with open(path, "wb") as f:
        f.write(uploadedfile.getbuffer())
    return path

# --- HÃ m xá»­ lÃ½ PDF ---
def extract_text_from_pdf(file_path):
    try:
        text = ""
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages[:3]:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text.strip()
    except Exception as e:
        st.error(f"Lá»—i khi Ä‘á»c file PDF: {str(e)}")
        return ""

# --- TrÃ­ch xuáº¥t tÃªn ---
def extract_name(text):
    lines = text.strip().split("\n")
    for line in lines[:10]:
        if re.search(r"(Name|TÃªn):", line, re.IGNORECASE):
            return line.split(":")[-1].strip()
    for line in lines[:10]:
        if len(line.split()) >= 2 and line[0].isupper():
            if not any(char.isdigit() for char in line) and len(line.split()) <= 5 and not any(kw in line.lower() for kw in ["contact", "information"]):
                return line.strip()
    return "KhÃ´ng rÃµ"

# --- PhÃ¢n loáº¡i lÄ©nh vá»±c ---
def predict_field(text_cv):
    if classifier is None:
        return "KhÃ´ng xÃ¡c Ä‘á»‹nh"
    short_text = text_cv[:300]
    result = classifier(short_text, candidate_labels=FIELDS)
    return result['labels'][0]

# --- TrÃ­ch xuáº¥t ká»¹ nÄƒng tá»« CV (tá»« má»¥c ká»¹ nÄƒng) ---
def extract_skills_list(text):
    skills = []
    for line in text.splitlines():
        if re.search(r'(skill|tools|tech|technology|framework)', line, re.IGNORECASE):
            parts = re.split(r'[:,]', line)
            if len(parts) > 1:
                items = re.split(r'[,/]', parts[1])
                items = [item.strip(" ()").strip() for item in items if item.strip()]
                skills.extend(items)
    return list(set(skills))

# --- TrÃ­ch xuáº¥t ká»¹ nÄƒng sá»­ dá»¥ng trong project ---
def extract_skills_from_projects(text):
    sections = re.findall(r"(?i)(project|dá»± Ã¡n)[^\n]*\n+(.*?)(?=\n{2,}|\Z)", text, re.DOTALL)
    all_skills = set()
    for _, section in sections:
        lines = section.split('\n')
        for line in lines:
            if any(kw in line.lower() for kw in ['stack', 'tech', 'technology', 'tools', 'framework', 'sá»­ dá»¥ng']):
                items = re.split(r'[:,]', line)
                if len(items) > 1:
                    for part in re.split(r'[,/â€¢]', items[1]):
                        skill = part.strip(" -â€¢()")
                        if 1 < len(skill) <= 30:
                            all_skills.add(skill)
    return sorted(all_skills)

# --- So khá»›p ká»¹ nÄƒng ---
def match_skills_accurately(candidate_skills, expected_skills):
    matched = [s for s in expected_skills if any(s.lower() in c.lower() for c in candidate_skills)]
    missing = [s for s in expected_skills if s not in matched]
    coverage = round(len(matched) / len(expected_skills) * 100, 2) if expected_skills else 0
    return matched, missing, coverage

# --- So khá»›p nghá» ---
def match_field(text_cv, target_field):
    predicted_field = predict_field(text_cv)
    return predicted_field.lower() == target_field.lower()

# --- Hiá»ƒn thá»‹ PDF ---
def display_pdf(file_path):
    with open(file_path, "rb") as f:
        base64_pdf = base64.b64encode(f.read()).decode('utf-8')
    pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="700" height="1000" type="application/pdf"></iframe>'
    st.markdown(pdf_display, unsafe_allow_html=True)

# --- PhÃ¢n tÃ­ch má»™t CV ---
def process_cv(file_path, expected_skills, target_field):
    text = extract_text_from_pdf(file_path)
    if text:
        if not match_field(text, target_field):
            return None
        name = extract_name(text)
        candidate_skills = extract_skills_list(text)
        project_skills = extract_skills_from_projects(text)
        total_skills = list(set(candidate_skills + project_skills))
        matched, missing, skill_coverage = match_skills_accurately(total_skills, expected_skills)
        final_coverage = skill_coverage
        if final_coverage == 0:
            return None
        result_status = "PhÃ¹ há»£p" if final_coverage >= 50 else "KhÃ´ng phÃ¹ há»£p"
        return {
            'TÃªn file': os.path.basename(file_path),
            'TÃªn á»©ng viÃªn': name,
            'Máº£ng IT': target_field,
            'Pháº§n trÄƒm phÃ¹ há»£p': final_coverage,
            'Káº¿t quáº£': result_status,
            'Ká»¹ nÄƒng phÃ¹ há»£p': ', '.join(matched),
            'Ká»¹ nÄƒng cÃ²n thiáº¿u': ', '.join(missing),
            'Ká»¹ nÄƒng trong project': ', '.join(project_skills)
        }
    return None

# --- PhÃ¢n tÃ­ch nhiá»u CV ---
@st.cache_data
def analyze_cvs(uploaded_paths, expected_skills, target_field):
    results = []
    warnings = []
    progress_bar = st.progress(0)
    total_files = len(uploaded_paths)
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(process_cv, path, expected_skills, target_field) for path in uploaded_paths]
        for i, future in enumerate(futures):
            result = future.result()
            if result:
                results.append(result)
            else:
                warnings.append(f"âš ï¸ CV táº¡i {uploaded_paths[i]} khÃ´ng Ä‘áº¡t tiÃªu chÃ­ vÃ  Ä‘Ã£ bá»‹ loáº¡i bá».")
            progress_bar.progress((i + 1) / total_files)
    if warnings:
        st.warning(f"âš ï¸ CÃ³ {len(warnings)} CV Ä‘Ã£ bá»‹ loáº¡i bá» do khÃ´ng Ä‘áº¡t tiÃªu chÃ­.")
        with st.expander("Xem chi tiáº¿t cÃ¡c cáº£nh bÃ¡o"):
            st.write("\n".join(warnings))
    return pd.DataFrame(results)

# --- Dashboard bÃ¡o cÃ¡o ---
def show_dashboard(df):
    st.header("ğŸ“Š Dashboard BÃ¡o cÃ¡o & PhÃ¢n tÃ­ch Káº¿t quáº£")
    st.dataframe(df)

    # Thá»‘ng kÃª tá»•ng quan
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Tá»•ng sá»‘ CV", len(df))
    col2.metric("Sá»‘ CV phÃ¹ há»£p", (df['Káº¿t quáº£'] == "PhÃ¹ há»£p").sum())
    col3.metric("Tá»‰ lá»‡ phÃ¹ há»£p", f"{(df['Káº¿t quáº£'] == 'PhÃ¹ há»£p').mean()*100:.1f}%")
    col4.metric("Sá»‘ lÄ©nh vá»±c", df['Máº£ng IT'].nunique())

    # Biá»ƒu Ä‘á»“ tá»‰ lá»‡ phÃ¹ há»£p
    st.subheader("Tá»‰ lá»‡ CV phÃ¹ há»£p/khÃ´ng phÃ¹ há»£p")
    status_counts = df['Káº¿t quáº£'].value_counts()
    fig1, ax1 = plt.subplots()
    ax1.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', startangle=90)
    ax1.axis('equal')
    st.pyplot(fig1)

    # Biá»ƒu Ä‘á»“ phÃ¢n bá»‘ lÄ©nh vá»±c IT
    st.subheader("PhÃ¢n bá»‘ lÄ©nh vá»±c IT")
    st.bar_chart(df['Máº£ng IT'].value_counts())

    # Top ká»¹ nÄƒng cÃ²n thiáº¿u
    st.subheader("Top ká»¹ nÄƒng cÃ²n thiáº¿u")
    missing_skills = []
    for skills in df['Ká»¹ nÄƒng cÃ²n thiáº¿u']:
        missing_skills.extend([s.strip() for s in str(skills).split(',') if s.strip()])
    top_missing = Counter(missing_skills).most_common(10)
    if top_missing:
        skills, counts = zip(*top_missing)
        st.bar_chart(pd.Series(counts, index=skills))
    else:
        st.info("KhÃ´ng cÃ³ ká»¹ nÄƒng cÃ²n thiáº¿u nÃ o ná»•i báº­t.")

    # Top ká»¹ nÄƒng phÃ¹ há»£p
    st.subheader("Top ká»¹ nÄƒng phÃ¹ há»£p")
    matched_skills = []
    for skills in df['Ká»¹ nÄƒng phÃ¹ há»£p']:
        matched_skills.extend([s.strip() for s in str(skills).split(',') if s.strip()])
    top_matched = Counter(matched_skills).most_common(10)
    if top_matched:
        skills, counts = zip(*top_matched)
        st.bar_chart(pd.Series(counts, index=skills))
    else:
        st.info("KhÃ´ng cÃ³ ká»¹ nÄƒng phÃ¹ há»£p ná»•i báº­t.")

# --- Giao diá»‡n chÃ­nh ---
def main():
    # Sidebar Ä‘áº¹p vá»›i option-menu vÃ  slogan
    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/3135/3135715.png", width=100)
        st.markdown("<div class='sidebar-title'>Há»‡ thá»‘ng Tuyá»ƒn dá»¥ng AI</div>", unsafe_allow_html=True)
        st.markdown("<div class='sidebar-desc'>Tá»‘i Æ°u hÃ³a quy trÃ¬nh tuyá»ƒn dá»¥ng, lá»c CV á»©ng viÃªn tá»± Ä‘á»™ng báº±ng AI.<br>Tiáº¿t kiá»‡m thá»i gian, nÃ¢ng cao hiá»‡u quáº£!</div>", unsafe_allow_html=True)
        menu = option_menu(
            None,
            ["PhÃ¢n tÃ­ch CV", "Dashboard bÃ¡o cÃ¡o"],
            icons=["file-earmark-text", "bar-chart"],
            menu_icon="cast", default_index=0,
            styles={
                "container": {"padding": "5px", "background-color": "#222"},
                "icon": {"color": "#00d4ff", "font-size": "20px"},
                "nav-link": {"font-size": "16px", "text-align": "left", "margin":"2px", "--hover-color": "#1e90ff"},
                "nav-link-selected": {"background-color": "#1e90ff", "color": "white"},
            }
        )

    st.title("ğŸ“„ Há»‡ thá»‘ng Há»— trá»£ Quáº£n lÃ½ Tuyá»ƒn dá»¥ng báº±ng AI")

    if menu == "PhÃ¢n tÃ­ch CV":
        st.header("ğŸ“„ PhÃ¢n tÃ­ch CV")
        st.markdown("> **BÆ°á»›c 1:** Táº£i lÃªn CV tiÃªu chÃ­ (chuáº©n).<br>**BÆ°á»›c 2:** Táº£i lÃªn cÃ¡c CV á»©ng viÃªn Ä‘á»ƒ lá»c tá»± Ä‘á»™ng.<br>**BÆ°á»›c 3:** Xem káº¿t quáº£, táº£i danh sÃ¡ch á»©ng viÃªn phÃ¹ há»£p.", unsafe_allow_html=True)
        sample_cv_file = st.file_uploader("ğŸ“Œ Táº£i lÃªn CV tiÃªu chÃ­", type="pdf")
        uploaded_files = st.file_uploader("ğŸ“… Táº£i lÃªn cÃ¡c CV á»©ng viÃªn", type=["pdf"], accept_multiple_files=True)

        if sample_cv_file and uploaded_files:
            sample_cv_path = save_uploadedfile(sample_cv_file)
            sample_cv_text = extract_text_from_pdf(sample_cv_path)
            expected_skills = extract_skills_list(sample_cv_text)
            target_field = predict_field(sample_cv_text)

            uploaded_paths = [save_uploadedfile(uploaded_file) for uploaded_file in uploaded_files]
            st.success(f"âœ… ÄÃ£ upload {len(uploaded_files)} CV á»©ng viÃªn.")

            with st.spinner("ğŸ” Äang tiáº¿n hÃ nh phÃ¢n tÃ­ch CV..."):
                my_bar = st.progress(0)
                df = analyze_cvs(uploaded_paths, expected_skills, target_field)
                my_bar.progress(1.0)

            st.subheader("ğŸ“Š TÃ³m táº¯t káº¿t quáº£")
            st.success(f"âœ… ÄÃ£ phÃ¢n tÃ­ch {len(df)} CV há»£p lá»‡ trÃªn tá»•ng sá»‘ {len(uploaded_files)} CV.")

            if df.empty:
                st.warning("âš ï¸ KhÃ´ng cÃ³ CV nÃ o phÃ¹ há»£p vá»›i tiÃªu chÃ­.")
            else:
                st.subheader("ğŸ“‹ Danh sÃ¡ch á»©ng viÃªn phÃ¹ há»£p")
                df.index = df.index + 1
                st.dataframe(df)

                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ“… Táº£i danh sÃ¡ch á»©ng viÃªn Ä‘Ã£ Ä‘Ã¡nh giÃ¡",
                    data=csv,
                    file_name='cv_filtered_results.csv',
                    mime='text/csv',
                )

                st.subheader("ğŸ” Xem chi tiáº¿t tá»«ng CV")
                selected_file = st.selectbox("Chá»n má»™t file CV Ä‘á»ƒ xem chi tiáº¿t:", df['TÃªn file'].tolist())

                if selected_file:
                    selected_path = next((path for path in uploaded_paths if os.path.basename(path) == selected_file), None)
                    if selected_path:
                        text = extract_text_from_pdf(selected_path)
                        if text:
                            st.write(f"### PhÃ¢n tÃ­ch chi tiáº¿t CV: {selected_file}")
                            st.write(f"- **TÃªn á»©ng viÃªn**: {extract_name(text)}")

                            st.write("### Ná»™i dung CV")
                            display_pdf(selected_path)

                            candidate_skills = extract_skills_list(text)
                            project_skills = extract_skills_from_projects(text)
                            total_skills = list(set(candidate_skills + project_skills))
                            matched, missing, skill_coverage = match_skills_accurately(total_skills, expected_skills)

                            st.write("### Tá»‰ lá»‡ phÃ¹ há»£p")
                            st.write(f"- **Tá»•ng**: {skill_coverage}%")

                            st.write("### Ká»¹ nÄƒng phÃ¹ há»£p")
                            st.write(", ".join(matched) if matched else "KhÃ´ng rÃµ")

                            st.write("### Ká»¹ nÄƒng cÃ²n thiáº¿u")
                            st.write(", ".join(missing) if missing else "KhÃ´ng rÃµ")

                            st.write("### Ká»¹ nÄƒng trong project")
                            st.write(", ".join(project_skills) if project_skills else "KhÃ´ng rÃµ")

            # LÆ°u DataFrame vÃ o session_state Ä‘á»ƒ dÃ¹ng cho dashboard náº¿u muá»‘n
            st.session_state['last_df'] = df

    elif menu == "Dashboard bÃ¡o cÃ¡o":
        st.header("ğŸ“Š Dashboard BÃ¡o cÃ¡o & PhÃ¢n tÃ­ch Káº¿t quáº£")
        st.markdown("> Táº£i lÃªn file káº¿t quáº£ phÃ¢n tÃ­ch (CSV) hoáº·c sá»­ dá»¥ng dá»¯ liá»‡u vá»«a phÃ¢n tÃ­ch Ä‘á»ƒ xem bÃ¡o cÃ¡o tá»•ng quan.", unsafe_allow_html=True)
        uploaded_csv = st.file_uploader("Táº£i lÃªn file káº¿t quáº£ phÃ¢n tÃ­ch (CSV)", type="csv")
        df = None
        if uploaded_csv:
            df = pd.read_csv(uploaded_csv)
        elif 'last_df' in st.session_state:
            df = st.session_state['last_df']
            st.info("Äang dÃ¹ng dá»¯ liá»‡u káº¿t quáº£ vá»«a phÃ¢n tÃ­ch.")
        if df is not None and not df.empty:
            show_dashboard(df)
        else:
            st.info("Vui lÃ²ng táº£i lÃªn file káº¿t quáº£ hoáº·c phÃ¢n tÃ­ch CV trÆ°á»›c.")

if __name__ == "__main__":
    main()