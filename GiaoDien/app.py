# üì¶ Import th∆∞ vi·ªán
import streamlit as st
import os
import pdfplumber
import base64
import re
from transformers import pipeline
import pandas as pd

# ‚ö° Set page config
st.set_page_config(page_title="H·ªá th·ªëng H·ªó tr·ª£ Tuy·ªÉn d·ª•ng b·∫±ng AI", layout="wide")

# üì• Folder l∆∞u CV
UPLOAD_FOLDER = './uploaded_cvs/'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# üìö Load model AI
@st.cache_resource
def load_classifier():
    return pipeline("zero-shot-classification", model="facebook/bart-large-mnli")

classifier = load_classifier()

FIELDS = ["IT"]

# --- H√†m x·ª≠ l√Ω ---
def extract_text_from_pdf(file_path):
    try:
        text = ""
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text.strip()
    except:
        return ""

def predict_field(text_cv):
    short_text = text_cv[:1000]
    result = classifier(short_text, candidate_labels=FIELDS)
    return result['labels'][0]

def extract_email(text):
    match = re.search(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', text)
    return match.group(0) if match else ""

def extract_name(text):
    lines = text.strip().split("\n")
    for line in lines:
        if len(line.split()) <= 5 and any(c.isalpha() for c in line):
            return line.strip()
    return "Kh√¥ng r√µ"

def save_uploadedfile(uploadedfile):
    path = os.path.join(UPLOAD_FOLDER, uploadedfile.name)
    with open(path, "wb") as f:
        f.write(uploadedfile.getbuffer())
    return path

def show_pdf(file_path):
    with open(file_path, "rb") as f:
        base64_pdf = base64.b64encode(f.read()).decode('utf-8')
    st.markdown(f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="700" height="1000"></iframe>', unsafe_allow_html=True)

# --- Giao di·ªán ch√≠nh ---
def main():
    st.title("üìÑ H·ªá th·ªëng H·ªó tr·ª£ Qu·∫£n l√Ω Tuy·ªÉn d·ª•ng b·∫±ng AI")

    st.sidebar.header("üì§ Upload CV (.pdf)")
    uploaded_files = st.sidebar.file_uploader("T·∫£i l√™n nhi·ªÅu CV", type=["pdf"], accept_multiple_files=True)

    cv_data = []

    if uploaded_files:
        uploaded_paths = []
        for uploaded_file in uploaded_files:
            path = save_uploadedfile(uploaded_file)
            uploaded_paths.append(path)
        st.sidebar.success(f"‚úÖ ƒê√£ upload {len(uploaded_files)} file CV.")

        st.success("‚úÖ ƒêang ti·∫øn h√†nh ph√¢n t√≠ch CV...")
        result_placeholder = st.empty()
        my_bar = st.progress(0)

        for idx, file_path in enumerate(uploaded_paths):
            text = extract_text_from_pdf(file_path)

            if text:
                try:
                    predicted_field = predict_field(text)
                    name = extract_name(text)
                    email = extract_email(text)

                    cv_data.append({
                        'T√™n file': os.path.basename(file_path),
                        'T√™n ·ª©ng vi√™n': name,
                        'Email': email,
                        'N·ªôi dung CV': text,
                        'Ng√†nh ngh·ªÅ': predicted_field,
                        'ƒê∆∞·ªùng d·∫´n': file_path
                    })
                except Exception as e:
                    st.error(f"L·ªói ph√¢n t√≠ch file {file_path}: {str(e)}")

            my_bar.progress((idx + 1) / len(uploaded_paths))
            result_placeholder.dataframe(pd.DataFrame(cv_data)[['T√™n file', 'T√™n ·ª©ng vi√™n', 'Email', 'Ng√†nh ngh·ªÅ']])

        my_bar.empty()
        st.toast("‚úÖ ƒê√£ ho√†n t·∫•t ph√¢n t√≠ch CV!", icon="‚úÖ")

    if cv_data:
        df = pd.DataFrame(cv_data)

        st.subheader("üåü Ch·ªçn ng√†nh ƒë·ªÉ l·ªçc")
        selected_field = st.selectbox("Ng√†nh ngh·ªÅ", FIELDS)

        filtered_df = df[df['Ng√†nh ngh·ªÅ'] == selected_field]

        st.subheader(f"üìã Danh s√°ch ·ª©ng vi√™n ng√†nh {selected_field}")
        st.dataframe(filtered_df[['T√™n file', 'T√™n ·ª©ng vi√™n', 'Email', 'Ng√†nh ngh·ªÅ']])

        csv = filtered_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üì• T·∫£i danh s√°ch ·ª©ng vi√™n",
            data=csv,
            file_name=f'cv_filtered_{selected_field}.csv',
            mime='text/csv',
        )

        st.markdown("---")

        st.subheader("üîç Ph√¢n t√≠ch chi ti·∫øt CV")
        selected_cv_file = st.selectbox("üìÇ Ch·ªçn CV ƒë·ªÉ ph√¢n t√≠ch", filtered_df['T√™n file'])

        if selected_cv_file:
            selected_cv = filtered_df[filtered_df['T√™n file'] == selected_cv_file].iloc[0]
            st.info(f"üî∏ ƒêang ph√¢n t√≠ch CV: {selected_cv['T√™n file']}")

            st.subheader("üñºÔ∏è Xem n·ªôi dung CV")
            show_pdf(selected_cv['ƒê∆∞·ªùng d·∫´n'])

            st.subheader("üßê ƒê√°nh gi√° k·ªπ nƒÉng ng√†nh IT")
            skills = ["python", "java", "c++", "javascript", "nodejs", "react", "sql", "django"]
            skill_count = sum(skill.lower() in selected_cv['N·ªôi dung CV'].lower() for skill in skills)

            st.success(f"üåü K·ªπ nƒÉng ph√π h·ª£p: {skill_count}/{len(skills)}")

            if skill_count >= 5:
                st.success("‚úÖ ·ª®ng vi√™n r·∫•t ph√π h·ª£p v·ªõi ng√†nh IT.")
            elif skill_count >= 2:
                st.info("‚ûñ ·ª®ng vi√™n c√≥ m·ªôt s·ªë k·ªπ nƒÉng ph√π h·ª£p.")
            else:
                st.warning("‚ö†Ô∏è ·ª®ng vi√™n thi·∫øu k·ªπ nƒÉng c·∫ßn thi·∫øt.")

if __name__ == "__main__":
    main()
